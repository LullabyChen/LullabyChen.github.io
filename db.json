{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/hipaper/source/css/comment.css","path":"css/comment.css","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/fashion.css","path":"css/fashion.css","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/glyphs.css","path":"css/glyphs.css","modified":0,"renderable":1},{"_id":"themes/hipaper/source/js/insight.js","path":"js/insight.js","modified":0,"renderable":1},{"_id":"themes/hipaper/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/hipaper/source/js/totop.js","path":"js/totop.js","modified":0,"renderable":1},{"_id":"themes/hipaper/source/preview/browser-support.png","path":"preview/browser-support.png","modified":0,"renderable":1},{"_id":"themes/hipaper/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/bootstrap.css","path":"css/bootstrap.css","modified":0,"renderable":1},{"_id":"themes/hipaper/source/js/bootstrap.js","path":"js/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/hipaper/source/js/jquery-3.1.1.min.js","path":"js/jquery-3.1.1.min.js","modified":0,"renderable":1},{"_id":"themes/hipaper/source/preview/code-theme-default.png","path":"preview/code-theme-default.png","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/images/favicon.ico","path":"css/images/favicon.ico","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/images/rocket.png","path":"css/images/rocket.png","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/fonts/athemes-glyphs.woff","path":"css/fonts/athemes-glyphs.woff","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/hipaper/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/hipaper/source/preview/logo-preview.jpg","path":"preview/logo-preview.jpg","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/hipaper/source/preview/search-preview.png","path":"preview/search-preview.png","modified":0,"renderable":1},{"_id":"themes/hipaper/source/preview/mobile-preview.png","path":"preview/mobile-preview.png","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/hipaper/source/preview/hipaper-preview.png","path":"preview/hipaper-preview.png","modified":0,"renderable":1},{"_id":"themes/hipaper/source/css/images/pose01.jpg","path":"css/images/pose01.jpg","modified":0,"renderable":1},{"_id":"themes/hipaper/source/preview/code-theme.jpg","path":"preview/code-theme.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"db6977b1ebb5cc2fecca0ddb2dc7204fcd1bfc93","modified":1554449581786},{"_id":"themes/hipaper/.DS_Store","hash":"df740dbafbc544384ba8587f50a154f242713772","modified":1548926429168},{"_id":"themes/hipaper/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1548334873066},{"_id":"themes/hipaper/.gitignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1548334873065},{"_id":"themes/hipaper/.travis.yml","hash":"24851843a40973daaee47b2697e8b0dc4e6556b3","modified":1548334873065},{"_id":"themes/hipaper/LICENSE","hash":"e84291eaaeb4a02004d4aa6a504cbf9475f5c562","modified":1548334873067},{"_id":"themes/hipaper/README.md","hash":"bf23afe909e5e2d3c6924265e77b626ac74b04fe","modified":1548334873068},{"_id":"themes/hipaper/package.json","hash":"8cc069bbca0f14fdbad2be17fe3a6d1eda1ee581","modified":1548334873093},{"_id":"themes/hipaper/_config.yml","hash":"d8aeb7f91dd8874e1aaa8bf3f90730c7c749e0c2","modified":1548925147370},{"_id":"source/_posts/Keras1.md","hash":"548860ea0e25c075442e623209bf0101e43940c4","modified":1548390215878},{"_id":"source/_posts/.DS_Store","hash":"9441637b2524a2b708b260ec21d09cb373c0ce2f","modified":1554449576776},{"_id":"themes/hipaper/README.cn.md","hash":"28c4d60bc6f78d55d3c7f316677c2f4c0c69780f","modified":1548334873067},{"_id":"source/_posts/Keras2.md","hash":"ca5f13fdaba6de0392cf0a759818c8ddbc5afa1b","modified":1550488827539},{"_id":"source/_posts/Keras4.md","hash":"910c163ef4bd5e0f41ccc92e6c62eaf96d255d0a","modified":1548677796333},{"_id":"source/_posts/Markdown空格.md","hash":"1831d538820912c9067848cb944af401c013eaf8","modified":1554449378981},{"_id":"source/_posts/Keras3.md","hash":"31b539c05caf6297fdd5073ec24f8470d50ad6f3","modified":1548677817788},{"_id":"source/_posts/Plugin1.md","hash":"a4cea482221395e277dea88f909e319eb070c834","modified":1548667727278},{"_id":"source/_posts/hello-world.md","hash":"d2d8fe939270ebbc4c54427d8f88d4697ef994b1","modified":1548327819496},{"_id":"source/tags/.DS_Store","hash":"bea841a25d3351c65341a57f219544ea99c3037a","modified":1548326214813},{"_id":"source/tags/index.md","hash":"f57e3cbe3b788aa640639b4068f3776e023d0aff","modified":1548923140202},{"_id":"source/categories/index.md","hash":"6d38a0767fcff1bcd2e6a37235427fc25fdcd129","modified":1548923236458},{"_id":"source/about/index.md","hash":"71329a2f6f8577243ead1bb7bc1ede941bafd66a","modified":1548929524166},{"_id":"themes/hipaper/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1548334873042},{"_id":"source/about/.DS_Store","hash":"63c66da9ddced6ec0529f6d685a68b74bf254419","modified":1548929750960},{"_id":"themes/hipaper/.git/FETCH_HEAD","hash":"2ed8dd7ba41d97f13db88f14ce870826386c04e3","modified":1548334881708},{"_id":"themes/hipaper/.git/ORIG_HEAD","hash":"bf1c1aba045f1ebbd049c021ce1458d72b1fec5b","modified":1548334881738},{"_id":"themes/hipaper/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1548334864005},{"_id":"themes/hipaper/.git/config","hash":"06972d529d212b478cb375302d437edd251fa86c","modified":1548334873050},{"_id":"themes/hipaper/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1548334873093},{"_id":"themes/hipaper/.git/packed-refs","hash":"8e850c636197788b2c62613fa5c2dc7bcc6866ea","modified":1548334873034},{"_id":"themes/hipaper/.git/index","hash":"f8b2d285f40ffca2cfe764898c6e5412059cb650","modified":1548334873154},{"_id":"themes/hipaper/source/.DS_Store","hash":"298d09d1380b7b6e63d604f9298379218f3fdc4e","modified":1548389364156},{"_id":"source/_posts/Keras1/.DS_Store","hash":"84dd9b1eb077bd9c0be54c0bcdf42565946356c2","modified":1548296678816},{"_id":"source/_posts/Keras1/install-python-3-6-2.png","hash":"6316ddfdf04bb6ac4737e5530494376a6504af8a","modified":1548262588600},{"_id":"source/_posts/Keras1/install-keras.png","hash":"532727a41f6fee20b2ca01e3e2442ef0a8fbf28d","modified":1548263065241},{"_id":"themes/hipaper/languages/de.yml","hash":"3ebf0775abbee928c8d7bda943c191d166ded0d3","modified":1548334873068},{"_id":"themes/hipaper/languages/en.yml","hash":"a7640a0c0c341fef694ed7367654cb5c2bde1af3","modified":1548334873069},{"_id":"themes/hipaper/languages/default.yml","hash":"a7640a0c0c341fef694ed7367654cb5c2bde1af3","modified":1548334873069},{"_id":"themes/hipaper/languages/fr.yml","hash":"84ab164b37c6abf625473e9a0c18f6f815dd5fd9","modified":1548334873070},{"_id":"themes/hipaper/languages/es.yml","hash":"76edb1171b86532ef12cfd15f5f2c1ac3949f061","modified":1548334873070},{"_id":"themes/hipaper/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1548334873070},{"_id":"themes/hipaper/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1548334873071},{"_id":"themes/hipaper/languages/pt.yml","hash":"46bd5f121f4704e2cd6c0950ec18b549f03bfe5c","modified":1548334873072},{"_id":"themes/hipaper/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1548334873073},{"_id":"themes/hipaper/languages/zh-TW.yml","hash":"ea111659185c7d0d9d1add6da9f19fdce6a1cb9e","modified":1548334873074},{"_id":"themes/hipaper/languages/zh-CN.yml","hash":"73c4a3d4ac3c5b89b096ed2cbea0dfce8586d2ad","modified":1548334873074},{"_id":"source/_posts/Keras4/output_11_0.png","hash":"4102c8fd94cf3751a68961e01608fea8e7f74d01","modified":1548677260000},{"_id":"source/_posts/Keras4/output_12_0.png","hash":"2037732ca040fd20d16f9ce9891b77043e98fb82","modified":1548677260000},{"_id":"source/_posts/Keras4/.DS_Store","hash":"111f12876f01cafafad71688aca49a76a147bb83","modified":1548677455478},{"_id":"source/_posts/Keras2/.DS_Store","hash":"ed74ee101c14543ee8a000a9fc827a0dfde7f63a","modified":1550554912550},{"_id":"source/_posts/Keras2/output_15_0.png","hash":"94d4f4327301a783d5b326299bc11684a375dded","modified":1548668132000},{"_id":"themes/hipaper/layout/.DS_Store","hash":"bd0a38704f46946cf0088f7a076fb886ee158c04","modified":1548930901246},{"_id":"themes/hipaper/layout/archive.ejs","hash":"bd3d87c361d3d0619516d2eaaf27d11b092b48a6","modified":1548334873087},{"_id":"themes/hipaper/layout/categories.ejs","hash":"05c63e56d49e80c08178728ad4552073e5f1c126","modified":1548334873087},{"_id":"themes/hipaper/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1548334873087},{"_id":"themes/hipaper/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1548334873088},{"_id":"themes/hipaper/layout/layout.ejs","hash":"beda9115367046f8b719c3b3ffb5bedb97f5d3c2","modified":1548334873088},{"_id":"themes/hipaper/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1548334873089},{"_id":"themes/hipaper/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1548334873089},{"_id":"themes/hipaper/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1548334873092},{"_id":"themes/hipaper/layout/tags.ejs","hash":"d98cb3bbc72dab15b1b518e30cfda58ef35c842e","modified":1548334873092},{"_id":"source/_posts/Keras3/output_12_0.png","hash":"165174aec90b2ab04097deeb25affa1852b5af3d","modified":1548677244000},{"_id":"source/_posts/Keras3/output_13_0.png","hash":"80e1e5314530f922c329b1a3e9818911fe7602c2","modified":1548677244000},{"_id":"source/_posts/Keras3/.DS_Store","hash":"2845ed610a8e5abcaf594e62b2d3b1e11bf8ee74","modified":1548677460578},{"_id":"source/_posts/Plugin1/.DS_Store","hash":"7cb43727000df66c02dd9323151968d26214e66f","modified":1548667660723},{"_id":"source/_posts/Plugin1/10.png","hash":"7452c83f25c7f2f2a979827fe49ec98a7be099da","modified":1548408689819},{"_id":"source/_posts/Plugin1/12.png","hash":"2e76539e50e7304e8fa01fe11b6d7aacd1da18c8","modified":1548661309733},{"_id":"source/_posts/Plugin1/11.png","hash":"ac6f45aa440bef873352b7ead00ebc60b03a7a74","modified":1548409721506},{"_id":"source/_posts/Plugin1/15.png","hash":"3d9aa5b8fec527738a0f54981186ec48bbb30bda","modified":1548662191759},{"_id":"source/_posts/Plugin1/16.png","hash":"f8c48647d3bc405ba5ad34b6be786bb1a87c9b50","modified":1548662418152},{"_id":"source/_posts/Plugin1/14.png","hash":"21bef5d42ab6c2c3ebb5765a70ee91848250725d","modified":1548662164623},{"_id":"source/_posts/Plugin1/18.png","hash":"314dcebbe437350560d9b7cc8039b7c9977065df","modified":1548663554931},{"_id":"source/_posts/Plugin1/17.png","hash":"310b37f6dd7fb571af798be9f5b7a84b564a7161","modified":1548662469559},{"_id":"source/_posts/Plugin1/19.png","hash":"91448d4e53d5f749867a0899cb3d269ffb1ad6d5","modified":1548663668438},{"_id":"source/_posts/Plugin1/3.png","hash":"e394cde4cc8375a0bcd885a26d714bc2c49c2379","modified":1548402417026},{"_id":"source/_posts/Plugin1/20.png","hash":"ca266ef3af1d0e7878f64865ff510451e095053e","modified":1548663963356},{"_id":"source/_posts/Plugin1/2.png","hash":"42d08e4daec48f0babce7cc7943b38503c7990c9","modified":1548402264429},{"_id":"source/_posts/Plugin1/4.png","hash":"9cd199c3154cda02665970b185afb8c8c1736440","modified":1548402720401},{"_id":"source/_posts/Plugin1/5.png","hash":"6172eedcc6467b98d3351466c6959d263005bc5f","modified":1548402776884},{"_id":"source/_posts/Plugin1/6.png","hash":"7d31fe92595de45eb6ea591846ed76e3f403f058","modified":1548164052939},{"_id":"source/_posts/Plugin1/7.png","hash":"8c6f68407f7a3784a88150a3aee052d8e45d299f","modified":1548405031245},{"_id":"source/_posts/Keras1/keras-test.png","hash":"b1b7014ab177bc93a1cf040b6ff42c2b0d49aba1","modified":1548263796348},{"_id":"source/_posts/Keras1/install-python-3-6.jpg","hash":"ec0be8d433536889aefaaeceab9df84e27c04aa3","modified":1548262198729},{"_id":"source/about/index/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1548929474968},{"_id":"source/_posts/Keras2/电影评级分类：二分类问题.pdf","hash":"896c8c0a25a54343b1de4a698f59aacfdfded346","modified":1550488504251},{"_id":"source/_posts/Plugin1/1.png","hash":"2fd43baffedd30b9b1fd2efffcb06adb40539d16","modified":1548402125318},{"_id":"source/_posts/Plugin1/13.png","hash":"35a543a70163b69325129effd5bcf2f20c86aea1","modified":1548409787557},{"_id":"themes/hipaper/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1548334864009},{"_id":"themes/hipaper/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1548334864006},{"_id":"themes/hipaper/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1548334864011},{"_id":"themes/hipaper/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1548334864008},{"_id":"themes/hipaper/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1548334864013},{"_id":"themes/hipaper/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1548334864007},{"_id":"themes/hipaper/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1548334864012},{"_id":"themes/hipaper/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1548334864009},{"_id":"themes/hipaper/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1548334864010},{"_id":"themes/hipaper/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1548334864014},{"_id":"themes/hipaper/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1548334864004},{"_id":"themes/hipaper/.git/logs/HEAD","hash":"9b5b6f64191b8798af944c5191753517af97c15b","modified":1548334873049},{"_id":"themes/hipaper/source/css/_extend.styl","hash":"b099bbeb871790dbc9e1e48533a1f9a52c767506","modified":1548334873094},{"_id":"themes/hipaper/source/css/_variables.styl","hash":"6299e27a2f5bb838f55fd756b74590b147aa1638","modified":1548334873098},{"_id":"themes/hipaper/source/css/comment.css","hash":"0f0d50e4153ce92b22ee18b214dfc76d8c386376","modified":1548334873100},{"_id":"themes/hipaper/source/css/.DS_Store","hash":"5d525168a0c25cf95085bd3e258c90f944446ca4","modified":1548389352108},{"_id":"themes/hipaper/source/css/fashion.css","hash":"3870e1ee8c850e92d9c3aa71d03afa7b0eef2a5c","modified":1548334873100},{"_id":"themes/hipaper/source/css/style.styl","hash":"68118d98ad5fa1b2e1b0dc83a96782711735ffe9","modified":1548334873115},{"_id":"themes/hipaper/source/css/glyphs.css","hash":"c4088f9a347e42a31d9aabc8aa17ead3d1ed8b8e","modified":1548334873110},{"_id":"themes/hipaper/source/js/insight.js","hash":"2995f3f94d0a9887b08e38a6f5053b6ca2997c19","modified":1548334873121},{"_id":"themes/hipaper/source/js/main.js","hash":"0c4ab8de5dd6a6733f0095036a90f5fff61c2261","modified":1548334873123},{"_id":"themes/hipaper/source/js/totop.js","hash":"560baaa7bbf70ce67261b39aef61293646d9e539","modified":1548334873124},{"_id":"themes/hipaper/source/preview/browser-support.png","hash":"a6d8498553550c6b18a8f22bcd2f53c993c7d677","modified":1548334873125},{"_id":"themes/hipaper/source/js/script.js","hash":"4964e125255a3f1afbf05728b331ad1fb1646e4d","modified":1548334873123},{"_id":"source/_posts/Plugin1/9.png","hash":"e04c4f6d20c8abc44b2c1fe9a2c75df94d1829de","modified":1548661139136},{"_id":"themes/hipaper/source/fancybox/.DS_Store","hash":"2e41b5d3b82b3f7de74bdd93a85b63e28be42839","modified":1548389359143},{"_id":"themes/hipaper/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1548334873116},{"_id":"themes/hipaper/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1548334873116},{"_id":"themes/hipaper/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1548334873117},{"_id":"themes/hipaper/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1548334873116},{"_id":"themes/hipaper/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1548334873117},{"_id":"themes/hipaper/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1548334873119},{"_id":"themes/hipaper/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1548334873117},{"_id":"themes/hipaper/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1548334873120},{"_id":"themes/hipaper/layout/_partial/after-footer.ejs","hash":"1ecf56b29969dab71727cee4ab81ac102b0f17b6","modified":1548334873075},{"_id":"themes/hipaper/layout/_partial/archive-post.ejs","hash":"29a9f178815ff7f9f1393d11afe016d7230a6b51","modified":1548334873075},{"_id":"themes/hipaper/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1548334873120},{"_id":"themes/hipaper/layout/_partial/article.ejs","hash":"4faa04e5c340f6290edc7227d77d3d2a7b4119f9","modified":1548335507949},{"_id":"themes/hipaper/layout/_partial/baidu-analytics.ejs","hash":"5776714a003d2b96b04b5399f67e0899d821247e","modified":1548334873077},{"_id":"themes/hipaper/layout/_partial/.DS_Store","hash":"7dfe72c3829313acbc64149929787c4b7a51c501","modified":1548926440139},{"_id":"themes/hipaper/layout/_partial/archive.ejs","hash":"ba641e2e4801bcc9df994d0596823af1982b5a00","modified":1548334873076},{"_id":"themes/hipaper/layout/_partial/facebook-sdk.ejs","hash":"06038db50d2e1febdefa3f8e1512b332c7da5a17","modified":1548334873079},{"_id":"themes/hipaper/layout/_partial/busuanzi-analytics.ejs","hash":"fd1eaae085c84733016737b11efe8e6b5b86ae63","modified":1548334873077},{"_id":"themes/hipaper/layout/_partial/comment.ejs","hash":"87bc07a72c95eeaff7f098fcb186c3ca1b1bc2ef","modified":1548334873079},{"_id":"themes/hipaper/layout/_partial/footer.ejs","hash":"eac1d939826ecf3af4b2852500917e2e40e0ef21","modified":1548334873079},{"_id":"themes/hipaper/layout/_partial/gauges-analytics.ejs","hash":"aad6312ac197d6c5aaf2104ac863d7eba46b772a","modified":1548334873080},{"_id":"themes/hipaper/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1548334873081},{"_id":"themes/hipaper/layout/_partial/head.ejs","hash":"016f344e5108d522cd012cebf7b9198f1104500d","modified":1548334873081},{"_id":"themes/hipaper/layout/_partial/header-post.ejs","hash":"b1af39790d209b5adff8757dcc97524e8fd0c60b","modified":1548334873082},{"_id":"themes/hipaper/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1548334873085},{"_id":"themes/hipaper/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1548334873082},{"_id":"themes/hipaper/layout/_partial/tencent-analytics.ejs","hash":"93120ad06c5d73ca777470faf570e993a805e049","modified":1548334873085},{"_id":"themes/hipaper/layout/_partial/cnzz-analytics.ejs","hash":"b0df992adf3c3c37189a66a98e6ef5ed06517ac4","modified":1548334873078},{"_id":"themes/hipaper/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1548334873085},{"_id":"themes/hipaper/layout/_widget/archive.ejs","hash":"9fffde4e794b35f07c96eaec6d9373a40014da8f","modified":1548334873085},{"_id":"themes/hipaper/layout/_widget/search.ejs","hash":"066b3e5f0abb4f6c91830bf910ee9c9ff8367ca1","modified":1548334873086},{"_id":"themes/hipaper/layout/_widget/social.ejs","hash":"875e82b6ae059e4f1d5627d29a00240182fe88a4","modified":1548334873086},{"_id":"themes/hipaper/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1548334873086},{"_id":"themes/hipaper/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1548334873086},{"_id":"themes/hipaper/layout/search/baidu.ejs","hash":"3e603a702d20c53fd3bcbeb570a16a86d54781ce","modified":1548334873089},{"_id":"themes/hipaper/layout/search/index.ejs","hash":"a8e098693007fbf7ad7896bcf463b0ba3af1a4b7","modified":1548334873090},{"_id":"themes/hipaper/layout/search/index-mobile.ejs","hash":"50a727ac1dfe3073eb6fa6699ba01e66f4ac41c0","modified":1548334873090},{"_id":"themes/hipaper/layout/search/insight.ejs","hash":"7d2a6d9639c08852345239d131784328ddf0493b","modified":1548334873091},{"_id":"source/_posts/Plugin1/8.png","hash":"76490321f75d89b50b622c9b8b97ccbe4c1d3803","modified":1548660643171},{"_id":"themes/hipaper/layout/search/swiftype.ejs","hash":"379e66d2c13526e72e4120c443f95fccf4edef71","modified":1548334873091},{"_id":"themes/hipaper/layout/_widget/recent_posts.ejs","hash":"5a3a3172f2b755cba35a6333179abec94f094a6e","modified":1548335870208},{"_id":"themes/hipaper/source/css/_partial/footer.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548334873096},{"_id":"themes/hipaper/source/css/_partial/header-post.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548334873096},{"_id":"themes/hipaper/source/css/_partial/header.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548334873096},{"_id":"themes/hipaper/source/css/bootstrap.css","hash":"afa4ed6bce62b265d08b0a5011558fe63e0bd289","modified":1548334873099},{"_id":"themes/hipaper/source/js/bootstrap.js","hash":"3b965a36a6b08854ad6eddedf85c5319fd392b4a","modified":1548334873121},{"_id":"themes/hipaper/source/js/jquery-3.1.1.min.js","hash":"f647a6d37dc4ca055ced3cf64bbc1f490070acba","modified":1548334873122},{"_id":"themes/hipaper/source/preview/code-theme-default.png","hash":"504991f74e6508f0516b655f0310e403e4248347","modified":1548334873127},{"_id":"themes/hipaper/.git/objects/pack/pack-57f3993586cea042b9cea274756dc94ab378e47b.idx","hash":"7d38efee9738828236d7615b9c6b75d4d5f987b2","modified":1548334872957},{"_id":"themes/hipaper/.git/refs/heads/master","hash":"bf1c1aba045f1ebbd049c021ce1458d72b1fec5b","modified":1548334873048},{"_id":"themes/hipaper/source/css/_partial/archive.styl","hash":"a5465e8a1f9969a14c6fb649d6443775c969b612","modified":1548334873094},{"_id":"themes/hipaper/source/css/_partial/article.styl","hash":"7b3835c3c8ddfce801014cd7288182e8d587f450","modified":1548334873095},{"_id":"themes/hipaper/source/css/_partial/comment.styl","hash":"f23dbf9c1224559314f7d10b7fee030a9ffab58a","modified":1548334873095},{"_id":"themes/hipaper/source/css/_partial/sidebar-aside.styl","hash":"a4f67e98dc244ba6119da065e69bcaf1a9066b94","modified":1548334873097},{"_id":"themes/hipaper/source/css/_partial/mobile.styl","hash":"fcfbaf24634519063af46953e0eb733a8ada5556","modified":1548334873097},{"_id":"themes/hipaper/source/css/_partial/highlight.styl","hash":"81d4b4431ad4ffff6937ac3b78f0effecd92b553","modified":1548334873096},{"_id":"themes/hipaper/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1548334873097},{"_id":"themes/hipaper/source/css/_partial/insight.styl","hash":"6da7629c668d7bcfbd527265906927e34b5043d5","modified":1548334873096},{"_id":"themes/hipaper/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1548334873097},{"_id":"themes/hipaper/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1548334873098},{"_id":"themes/hipaper/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1548334873098},{"_id":"themes/hipaper/source/css/images/favicon.ico","hash":"55db8e7a607d37486f73e967e9389cd6578009cf","modified":1548334873111},{"_id":"themes/hipaper/source/css/images/rocket.png","hash":"6dee0406955aa9b7a261161d30f2538a671e806b","modified":1548334873115},{"_id":"themes/hipaper/source/css/fonts/athemes-glyphs.woff","hash":"f1ac9ffcc97571ceff48b68792c34de97bc289c0","modified":1548334873103},{"_id":"themes/hipaper/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1548334873103},{"_id":"themes/hipaper/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1548334873104},{"_id":"themes/hipaper/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1548334873118},{"_id":"themes/hipaper/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1548334873117},{"_id":"themes/hipaper/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1548334873110},{"_id":"themes/hipaper/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1548334873118},{"_id":"themes/hipaper/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1548334873118},{"_id":"themes/hipaper/layout/_partial/post/category.ejs","hash":"7d167be432a0f41034f7e34ea33eb8748202358d","modified":1548334873083},{"_id":"themes/hipaper/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1548334873119},{"_id":"themes/hipaper/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1548334873119},{"_id":"themes/hipaper/layout/_partial/post/date.ejs","hash":"fe3cf76bb84d85112997320628d87f024b5e3a45","modified":1548334873083},{"_id":"themes/hipaper/layout/_partial/post/mathjax.ejs","hash":"571c19f57c2b38ac5cd9b8f811cfad53b38616cf","modified":1548334873083},{"_id":"themes/hipaper/layout/_partial/post/busuanzi-analytics.ejs","hash":"125fcedc8baf7dc67587c2ded05bfa8df868989a","modified":1548334873082},{"_id":"themes/hipaper/layout/_partial/post/gallery.ejs","hash":"5bbedaa4c01e905958b640bcf9bdcadab7b466e1","modified":1548390140504},{"_id":"themes/hipaper/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1548334873084},{"_id":"themes/hipaper/layout/_partial/post/tag.ejs","hash":"e6ab2d49029ed4b15204f84928b14b036a0c9c84","modified":1548334873084},{"_id":"themes/hipaper/layout/_partial/post/urlconvert.ejs","hash":"2133f1029632417f9043b9d4749d580ed0c75db0","modified":1548334873084},{"_id":"themes/hipaper/layout/_partial/post/title.ejs","hash":"7680b2258c9e1a9eb567b79c6812c5e836dd9740","modified":1548926602244},{"_id":"themes/hipaper/source/preview/logo-preview.jpg","hash":"7dde15dc09c11162c3f28fe8516c879ddd7d8e60","modified":1548334873147},{"_id":"themes/hipaper/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1548334873109},{"_id":"themes/hipaper/source/preview/search-preview.png","hash":"833e34fdebadb15609fc758ff5786b2c713e0ecc","modified":1548334873152},{"_id":"themes/hipaper/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1548334873040},{"_id":"themes/hipaper/.git/logs/refs/heads/master","hash":"9b5b6f64191b8798af944c5191753517af97c15b","modified":1548334873049},{"_id":"themes/hipaper/source/preview/mobile-preview.png","hash":"cf7b24d88aa28b71dbcafda2371d70ef97052e21","modified":1548334873150},{"_id":"themes/hipaper/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1548334873106},{"_id":"themes/hipaper/source/preview/hipaper-preview.png","hash":"12d42037cb2758ec395342ca55009e092c3d013f","modified":1548334873142},{"_id":"themes/hipaper/.git/logs/refs/remotes/origin/HEAD","hash":"9b5b6f64191b8798af944c5191753517af97c15b","modified":1548334873039},{"_id":"themes/hipaper/source/css/images/pose01.jpg","hash":"8c2a604c149850ee3fa0abb25b43b77093bd1772","modified":1548334873114},{"_id":"source/_posts/Keras2/0.png","hash":"5260145f153823ed86b18555214e817f58b0453d","modified":1453115442000},{"_id":"themes/hipaper/source/preview/code-theme.jpg","hash":"8c8512fd04e6106033656d10e92d51de76cca6d8","modified":1548334873136},{"_id":"source/_posts/Plugin1/0.png","hash":"50f122fd0b65c43f6882ee6a718919ea70edbcf3","modified":1453113319000},{"_id":"source/_posts/Keras1/1.png","hash":"9293a61b38107fa63bc61d5f4468b94f33f312ab","modified":1458321012000},{"_id":"themes/hipaper/.git/objects/pack/pack-57f3993586cea042b9cea274756dc94ab378e47b.pack","hash":"8aa53b92f84bb8e3d892dace891d49e53609aee3","modified":1548334872954},{"_id":"public/content.json","hash":"7a9920f4eb39de9dde7d2e69e24f85f463eafcb9","modified":1566532425845},{"_id":"public/tags/index.html","hash":"98277b1301992d1d08d5ac67fc2c1968258017ca","modified":1566532426234},{"_id":"public/about/index.html","hash":"56e49609722c66b80700373ce4ecb47eb2c8eaa9","modified":1566532426234},{"_id":"public/categories/index.html","hash":"06f7d9481463f71344c4bd3f5e652cfca2b82de7","modified":1566532426375},{"_id":"public/2019/01/28/Keras4/index.html","hash":"4a33afcbb6a0c3556a8d1cdbc6800c7aff5b9be9","modified":1566532426376},{"_id":"public/2019/04/05/Markdown空格/index.html","hash":"782f2e48d501e61115c3455f77d5d7e0de29f3a0","modified":1566532426382},{"_id":"public/2019/01/24/Keras1/index.html","hash":"068bf990a3eff79d98ac0baeb1d062dc65bb5153","modified":1566532426382},{"_id":"public/2019/01/18/hello-world/index.html","hash":"c54f30bc78674570f76c2e5529e554fa7e1bcd05","modified":1566532426382},{"_id":"public/2019/01/28/Keras3/index.html","hash":"d6fe996b62b0e8879c80abe475294b9cb3e9d55e","modified":1566532426382},{"_id":"public/2019/01/28/Keras2/index.html","hash":"98098d429b87c8e9af143c6d83d05cc9e87cc2f5","modified":1566532426383},{"_id":"public/2019/01/27/Plugin1/index.html","hash":"84a256224729843b66e26a77857b95b0cecbdcb6","modified":1566532426383},{"_id":"public/archives/index.html","hash":"b89df3bd74eb82ddb676a868327bf93dfad7a7b0","modified":1566532426384},{"_id":"public/archives/2019/04/index.html","hash":"29d2d3390cb496c875b8e4d41e9895c8fd13f190","modified":1566532426384},{"_id":"public/archives/2019/index.html","hash":"a538af444e7191141b17b6d7a9b7e7484032985f","modified":1566532426384},{"_id":"public/index.html","hash":"570384f25939809ae77ecfd2ed3220b753b461f3","modified":1566532426384},{"_id":"public/categories/Notes/index.html","hash":"d73bf32beebcf6ddd8abca09053d84306ada42d9","modified":1566532426384},{"_id":"public/archives/2019/01/index.html","hash":"7820957b8b1c329d2a7304f496222d2d51630601","modified":1566532426384},{"_id":"public/tags/Keras/index.html","hash":"66cbd5a4044eb75c9668ab51771edde4edf2fb23","modified":1566532426384},{"_id":"public/tags/Intellij-Plugin/index.html","hash":"4d19a33913e52ecfa9767bc9c63a5abf8fae9477","modified":1566532426384}],"Category":[{"name":"Notes","_id":"cju3r7xhe0004apndyt4xlfos"}],"Data":[],"Page":[{"title":"tags","date":"2019-01-24T04:04:04.000Z","layout":"tags","comments":0,"_content":"\n","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-01-24 12:04:04\nlayout: \"tags\"\ncomments: false\n---\n\n","updated":"2019-01-31T08:25:40.202Z","path":"tags/index.html","_id":"cju3r7xh90001apndz9bgt9k6","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2019-01-24T04:04:56.000Z","layout":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-01-24 12:04:56\nlayout: \"categories\"\ncomments: false\n---\n","updated":"2019-01-31T08:27:16.458Z","path":"categories/index.html","_id":"cju3r7xhc0003apndlabsmwjo","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"About","date":"2019-01-24T04:02:05.000Z","comments":0,"_content":"\n### 个人信息\n\n*****\n\n- Email: [LullabyChen1104.gmail.com](LullabyChen1104.gmail.com)\n\n- Github: [LullabyChen](https://github.com/LullabyChen)\n\n","source":"about/index.md","raw":"---\ntitle: About\ndate: 2019-01-24 12:02:05\ncomments: false\n---\n\n### 个人信息\n\n*****\n\n- Email: [LullabyChen1104.gmail.com](LullabyChen1104.gmail.com)\n\n- Github: [LullabyChen](https://github.com/LullabyChen)\n\n","updated":"2019-01-31T10:12:04.166Z","path":"about/index.html","layout":"page","_id":"cju3r7xhi0007apnd55lpzcdy","content":"<h3 id=\"个人信息\"><a href=\"#个人信息\" class=\"headerlink\" title=\"个人信息\"></a>个人信息</h3><hr>\n<ul>\n<li><p>Email: <a href=\"LullabyChen1104.gmail.com\">LullabyChen1104.gmail.com</a></p>\n</li>\n<li><p>Github: <a href=\"https://github.com/LullabyChen\" target=\"_blank\" rel=\"noopener\">LullabyChen</a></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"个人信息\"><a href=\"#个人信息\" class=\"headerlink\" title=\"个人信息\"></a>个人信息</h3><hr>\n<ul>\n<li><p>Email: <a href=\"LullabyChen1104.gmail.com\">LullabyChen1104.gmail.com</a></p>\n</li>\n<li><p>Github: <a href=\"https://github.com/LullabyChen\" target=\"_blank\" rel=\"noopener\">LullabyChen</a></p>\n</li>\n</ul>\n"}],"Post":[{"title":"KERAS学习（二）：电影评级分类-二分类问题","date":"2019-01-28T11:42:55.000Z","photos":["0.png"],"_content":"\n\n\n```python\n#加载IMDB数据集\nfrom keras.datasets import imdb\n(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n```\n\n```\nUsing TensorFlow backend.\n```\n\n<!-- more -->\n\n```python\ntrain_data[0]\n```\n\n\n\n```\n[1,\n 14,\n 22,\n 16,\n 43,\n 530,\n 973,\n 1622,\n 1385,\n 65,\n 458,\n 4468,\n 66,\n 3941,\n 4,\n 173,\n 36,\n 256,\n 5,\n 25,\n 100,\n 43,\n 838,\n 112,\n 50,\n 670,\n 2,\n 9,\n 35,\n 480,\n 284,\n 5,\n 150,\n 4,\n 172,\n 112,\n 167,\n 2,\n 336,\n 385,\n 39,\n 4,\n 172,\n 4536,\n 1111,\n 17,\n 546,\n 38,\n 13,\n 447,\n 4,\n 192,\n 50,\n 16,\n 6,\n 147,\n 2025,\n 19,\n 14,\n 22,\n 4,\n 1920,\n 4613,\n 469,\n 4,\n 22,\n 71,\n 87,\n 12,\n 16,\n 43,\n 530,\n 38,\n 76,\n 15,\n 13,\n 1247,\n 4,\n 22,\n 17,\n 515,\n 17,\n 12,\n 16,\n 626,\n 18,\n 2,\n 5,\n 62,\n 386,\n 12,\n 8,\n 316,\n 8,\n 106,\n 5,\n 4,\n 2223,\n 5244,\n 16,\n 480,\n 66,\n 3785,\n 33,\n 4,\n 130,\n 12,\n 16,\n 38,\n 619,\n 5,\n 25,\n 124,\n 51,\n 36,\n 135,\n 48,\n 25,\n 1415,\n 33,\n 6,\n 22,\n 12,\n 215,\n 28,\n 77,\n 52,\n 5,\n 14,\n 407,\n 16,\n 82,\n 2,\n 8,\n 4,\n 107,\n 117,\n 5952,\n 15,\n 256,\n 4,\n 2,\n 7,\n 3766,\n 5,\n 723,\n 36,\n 71,\n 43,\n 530,\n 476,\n 26,\n 400,\n 317,\n 46,\n 7,\n 4,\n 2,\n 1029,\n 13,\n 104,\n 88,\n 4,\n 381,\n 15,\n 297,\n 98,\n 32,\n 2071,\n 56,\n 26,\n 141,\n 6,\n 194,\n 7486,\n 18,\n 4,\n 226,\n 22,\n 21,\n 134,\n 476,\n 26,\n 480,\n 5,\n 144,\n 30,\n 5535,\n 18,\n 51,\n 36,\n 28,\n 224,\n 92,\n 25,\n 104,\n 4,\n 226,\n 65,\n 16,\n 38,\n 1334,\n 88,\n 12,\n 16,\n 283,\n 5,\n 16,\n 4472,\n 113,\n 103,\n 32,\n 15,\n 16,\n 5345,\n 19,\n 178,\n 32]\n```\n\n\n\n```python\ntrain_labels\n```\n\n\n\n```\narray([1, 0, 0, ..., 0, 1, 0])\n```\n\n\n\n```python\nmax([max(sequence) for sequence in train_data])\n```\n\n\n\n```\n9999\n```\n\n\n\n```python\n#索引解码成单词\nword_index = imdb.get_word_index()\nreverse_word_index = dict(\n    [(value, key) for (key, value) in word_index.items()])\ndecoded_review = ' '.join(\n    [reverse_word_index.get(i - 3, '?') for i in train_data[0]])  #第一个评论\n\n```\n\n```python\ndecoded_review\n\n```\n\n\n\n```\n\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\"\n\n```\n\n\n\n```python\n#数据向量化\nimport numpy as np\ndef vectorize_sequences(sequences, dimension=10000):\n    results= np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1.\n    return results\n\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)\n\n```\n\n```python\nx_train[0]\n\n```\n\n\n\n```\narray([0., 1., 1., ..., 0., 0., 0.])\n\n```\n\n\n\n```python\n#标签向量化\ny_train = np.asarray(train_labels).astype('float32')\ny_test = np.asarray(test_labels).astype('float32')\n\n```\n\n```python\n#构建网络 模型定义\n#激活函数relu 所有负值归0\n#任意值“压缩”到[0, 1]区间内\nfrom keras import models\nfrom keras import layers\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n#relu 负值归零 sigmoid 任意值压缩到[0, 1]区间内\n\n```\n\n```python\n#损失函数 优化器 指标 编译模型\n#\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\n```\n\n```python\n#从训练数据中留出验证集\nx_val = x_train[:10000]\npartial_x_train = x_train[10000:]\n\ny_val = y_train[:10000]\npartial_y_train = y_train[10000:]\n\n```\n\n```python\n#训练模型\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\nhistory = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))\n\n```\n\n```\nTrain on 15000 samples, validate on 10000 samples\nEpoch 1/20\n15000/15000 [==============================] - 6s 421us/step - loss: 0.5083 - acc: 0.7819 - val_loss: 0.3788 - val_acc: 0.8690\nEpoch 2/20\n15000/15000 [==============================] - 5s 311us/step - loss: 0.3001 - acc: 0.9048 - val_loss: 0.3000 - val_acc: 0.8901\nEpoch 3/20\n15000/15000 [==============================] - 4s 257us/step - loss: 0.2178 - acc: 0.9284 - val_loss: 0.3082 - val_acc: 0.8715\nEpoch 4/20\n15000/15000 [==============================] - 3s 221us/step - loss: 0.1750 - acc: 0.9435 - val_loss: 0.2838 - val_acc: 0.8839\nEpoch 5/20\n15000/15000 [==============================] - 4s 241us/step - loss: 0.1425 - acc: 0.9543 - val_loss: 0.2850 - val_acc: 0.8865\nEpoch 6/20\n15000/15000 [==============================] - 3s 222us/step - loss: 0.1149 - acc: 0.9652 - val_loss: 0.3163 - val_acc: 0.8773\nEpoch 7/20\n15000/15000 [==============================] - 4s 265us/step - loss: 0.0978 - acc: 0.9710 - val_loss: 0.3130 - val_acc: 0.8847\nEpoch 8/20\n15000/15000 [==============================] - 3s 231us/step - loss: 0.0807 - acc: 0.9765 - val_loss: 0.3861 - val_acc: 0.8653\nEpoch 9/20\n15000/15000 [==============================] - 3s 215us/step - loss: 0.0660 - acc: 0.9820 - val_loss: 0.3636 - val_acc: 0.8782\nEpoch 10/20\n15000/15000 [==============================] - 4s 254us/step - loss: 0.0555 - acc: 0.9852 - val_loss: 0.3845 - val_acc: 0.8790\nEpoch 11/20\n15000/15000 [==============================] - 3s 194us/step - loss: 0.0449 - acc: 0.9888 - val_loss: 0.4167 - val_acc: 0.8766\nEpoch 12/20\n15000/15000 [==============================] - 4s 247us/step - loss: 0.0385 - acc: 0.9913 - val_loss: 0.4511 - val_acc: 0.8700\nEpoch 13/20\n15000/15000 [==============================] - 4s 251us/step - loss: 0.0298 - acc: 0.9927 - val_loss: 0.4705 - val_acc: 0.8727\nEpoch 14/20\n15000/15000 [==============================] - 4s 259us/step - loss: 0.0244 - acc: 0.9949 - val_loss: 0.5029 - val_acc: 0.8723\nEpoch 15/20\n15000/15000 [==============================] - 3s 233us/step - loss: 0.0177 - acc: 0.9979 - val_loss: 0.5375 - val_acc: 0.8692\nEpoch 16/20\n15000/15000 [==============================] - 4s 239us/step - loss: 0.0170 - acc: 0.9967 - val_loss: 0.5728 - val_acc: 0.8702\nEpoch 17/20\n15000/15000 [==============================] - 3s 196us/step - loss: 0.0093 - acc: 0.9995 - val_loss: 0.6176 - val_acc: 0.8654\nEpoch 18/20\n15000/15000 [==============================] - 3s 224us/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.6386 - val_acc: 0.8669\nEpoch 19/20\n15000/15000 [==============================] - 3s 211us/step - loss: 0.0069 - acc: 0.9992 - val_loss: 0.7420 - val_acc: 0.8559\nEpoch 20/20\n15000/15000 [==============================] - 4s 238us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.6976 - val_acc: 0.8655\n\n```\n\n\n\n```python\n#绘制训练损失和验证损失\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs = range(1, len(loss_values) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'b', label='Valifation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n```\n\n```\n<Figure size 640x480 with 1 Axes>\n\n```\n\n\n\n```python\nhistory_dict.keys()\n\n```\n\n\n\n```\ndict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n\n```\n\n\n\n```python\n#绘制训练精度和验证精度\nplt.clf()\nacc = history_dict['acc']\nval_acc = history_dict['val_acc']\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n```\n\n![png](Keras2/output_15_0.png)\n\n\n\n```python\nresults = model.evaluate(x_test, y_test)\nresults\n\n```\n\n```\n25000/25000 [==============================] - 7s 272us/step\n\n```\n\n\n\n\n\n```\n[0.768154475197792, 0.85032]\n\n```\n\n\n\n```python\n#预测评价正面的可能性\nmodel.predict(x_test)\n\n```\n\n\n\n```\narray([[0.00997098],\n       [0.9999999 ],\n       [0.971289  ],\n       ...,\n       [0.00219277],\n       [0.0054981 ],\n       [0.72482127]], dtype=float32)\n\n```\n\n\n\n![](Keras2/电影评级分类：二分类问题.pdf)","source":"_posts/Keras2.md","raw":"---\ntitle: KERAS学习（二）：电影评级分类-二分类问题\ndate: 2019-01-28 19:42:55\ntags:\n    - Keras\ncategories:\n    - Notes\nphotos:\n    - 0.png\n---\n\n\n\n```python\n#加载IMDB数据集\nfrom keras.datasets import imdb\n(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n```\n\n```\nUsing TensorFlow backend.\n```\n\n<!-- more -->\n\n```python\ntrain_data[0]\n```\n\n\n\n```\n[1,\n 14,\n 22,\n 16,\n 43,\n 530,\n 973,\n 1622,\n 1385,\n 65,\n 458,\n 4468,\n 66,\n 3941,\n 4,\n 173,\n 36,\n 256,\n 5,\n 25,\n 100,\n 43,\n 838,\n 112,\n 50,\n 670,\n 2,\n 9,\n 35,\n 480,\n 284,\n 5,\n 150,\n 4,\n 172,\n 112,\n 167,\n 2,\n 336,\n 385,\n 39,\n 4,\n 172,\n 4536,\n 1111,\n 17,\n 546,\n 38,\n 13,\n 447,\n 4,\n 192,\n 50,\n 16,\n 6,\n 147,\n 2025,\n 19,\n 14,\n 22,\n 4,\n 1920,\n 4613,\n 469,\n 4,\n 22,\n 71,\n 87,\n 12,\n 16,\n 43,\n 530,\n 38,\n 76,\n 15,\n 13,\n 1247,\n 4,\n 22,\n 17,\n 515,\n 17,\n 12,\n 16,\n 626,\n 18,\n 2,\n 5,\n 62,\n 386,\n 12,\n 8,\n 316,\n 8,\n 106,\n 5,\n 4,\n 2223,\n 5244,\n 16,\n 480,\n 66,\n 3785,\n 33,\n 4,\n 130,\n 12,\n 16,\n 38,\n 619,\n 5,\n 25,\n 124,\n 51,\n 36,\n 135,\n 48,\n 25,\n 1415,\n 33,\n 6,\n 22,\n 12,\n 215,\n 28,\n 77,\n 52,\n 5,\n 14,\n 407,\n 16,\n 82,\n 2,\n 8,\n 4,\n 107,\n 117,\n 5952,\n 15,\n 256,\n 4,\n 2,\n 7,\n 3766,\n 5,\n 723,\n 36,\n 71,\n 43,\n 530,\n 476,\n 26,\n 400,\n 317,\n 46,\n 7,\n 4,\n 2,\n 1029,\n 13,\n 104,\n 88,\n 4,\n 381,\n 15,\n 297,\n 98,\n 32,\n 2071,\n 56,\n 26,\n 141,\n 6,\n 194,\n 7486,\n 18,\n 4,\n 226,\n 22,\n 21,\n 134,\n 476,\n 26,\n 480,\n 5,\n 144,\n 30,\n 5535,\n 18,\n 51,\n 36,\n 28,\n 224,\n 92,\n 25,\n 104,\n 4,\n 226,\n 65,\n 16,\n 38,\n 1334,\n 88,\n 12,\n 16,\n 283,\n 5,\n 16,\n 4472,\n 113,\n 103,\n 32,\n 15,\n 16,\n 5345,\n 19,\n 178,\n 32]\n```\n\n\n\n```python\ntrain_labels\n```\n\n\n\n```\narray([1, 0, 0, ..., 0, 1, 0])\n```\n\n\n\n```python\nmax([max(sequence) for sequence in train_data])\n```\n\n\n\n```\n9999\n```\n\n\n\n```python\n#索引解码成单词\nword_index = imdb.get_word_index()\nreverse_word_index = dict(\n    [(value, key) for (key, value) in word_index.items()])\ndecoded_review = ' '.join(\n    [reverse_word_index.get(i - 3, '?') for i in train_data[0]])  #第一个评论\n\n```\n\n```python\ndecoded_review\n\n```\n\n\n\n```\n\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\"\n\n```\n\n\n\n```python\n#数据向量化\nimport numpy as np\ndef vectorize_sequences(sequences, dimension=10000):\n    results= np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1.\n    return results\n\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)\n\n```\n\n```python\nx_train[0]\n\n```\n\n\n\n```\narray([0., 1., 1., ..., 0., 0., 0.])\n\n```\n\n\n\n```python\n#标签向量化\ny_train = np.asarray(train_labels).astype('float32')\ny_test = np.asarray(test_labels).astype('float32')\n\n```\n\n```python\n#构建网络 模型定义\n#激活函数relu 所有负值归0\n#任意值“压缩”到[0, 1]区间内\nfrom keras import models\nfrom keras import layers\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n#relu 负值归零 sigmoid 任意值压缩到[0, 1]区间内\n\n```\n\n```python\n#损失函数 优化器 指标 编译模型\n#\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\n```\n\n```python\n#从训练数据中留出验证集\nx_val = x_train[:10000]\npartial_x_train = x_train[10000:]\n\ny_val = y_train[:10000]\npartial_y_train = y_train[10000:]\n\n```\n\n```python\n#训练模型\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\nhistory = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))\n\n```\n\n```\nTrain on 15000 samples, validate on 10000 samples\nEpoch 1/20\n15000/15000 [==============================] - 6s 421us/step - loss: 0.5083 - acc: 0.7819 - val_loss: 0.3788 - val_acc: 0.8690\nEpoch 2/20\n15000/15000 [==============================] - 5s 311us/step - loss: 0.3001 - acc: 0.9048 - val_loss: 0.3000 - val_acc: 0.8901\nEpoch 3/20\n15000/15000 [==============================] - 4s 257us/step - loss: 0.2178 - acc: 0.9284 - val_loss: 0.3082 - val_acc: 0.8715\nEpoch 4/20\n15000/15000 [==============================] - 3s 221us/step - loss: 0.1750 - acc: 0.9435 - val_loss: 0.2838 - val_acc: 0.8839\nEpoch 5/20\n15000/15000 [==============================] - 4s 241us/step - loss: 0.1425 - acc: 0.9543 - val_loss: 0.2850 - val_acc: 0.8865\nEpoch 6/20\n15000/15000 [==============================] - 3s 222us/step - loss: 0.1149 - acc: 0.9652 - val_loss: 0.3163 - val_acc: 0.8773\nEpoch 7/20\n15000/15000 [==============================] - 4s 265us/step - loss: 0.0978 - acc: 0.9710 - val_loss: 0.3130 - val_acc: 0.8847\nEpoch 8/20\n15000/15000 [==============================] - 3s 231us/step - loss: 0.0807 - acc: 0.9765 - val_loss: 0.3861 - val_acc: 0.8653\nEpoch 9/20\n15000/15000 [==============================] - 3s 215us/step - loss: 0.0660 - acc: 0.9820 - val_loss: 0.3636 - val_acc: 0.8782\nEpoch 10/20\n15000/15000 [==============================] - 4s 254us/step - loss: 0.0555 - acc: 0.9852 - val_loss: 0.3845 - val_acc: 0.8790\nEpoch 11/20\n15000/15000 [==============================] - 3s 194us/step - loss: 0.0449 - acc: 0.9888 - val_loss: 0.4167 - val_acc: 0.8766\nEpoch 12/20\n15000/15000 [==============================] - 4s 247us/step - loss: 0.0385 - acc: 0.9913 - val_loss: 0.4511 - val_acc: 0.8700\nEpoch 13/20\n15000/15000 [==============================] - 4s 251us/step - loss: 0.0298 - acc: 0.9927 - val_loss: 0.4705 - val_acc: 0.8727\nEpoch 14/20\n15000/15000 [==============================] - 4s 259us/step - loss: 0.0244 - acc: 0.9949 - val_loss: 0.5029 - val_acc: 0.8723\nEpoch 15/20\n15000/15000 [==============================] - 3s 233us/step - loss: 0.0177 - acc: 0.9979 - val_loss: 0.5375 - val_acc: 0.8692\nEpoch 16/20\n15000/15000 [==============================] - 4s 239us/step - loss: 0.0170 - acc: 0.9967 - val_loss: 0.5728 - val_acc: 0.8702\nEpoch 17/20\n15000/15000 [==============================] - 3s 196us/step - loss: 0.0093 - acc: 0.9995 - val_loss: 0.6176 - val_acc: 0.8654\nEpoch 18/20\n15000/15000 [==============================] - 3s 224us/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.6386 - val_acc: 0.8669\nEpoch 19/20\n15000/15000 [==============================] - 3s 211us/step - loss: 0.0069 - acc: 0.9992 - val_loss: 0.7420 - val_acc: 0.8559\nEpoch 20/20\n15000/15000 [==============================] - 4s 238us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.6976 - val_acc: 0.8655\n\n```\n\n\n\n```python\n#绘制训练损失和验证损失\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs = range(1, len(loss_values) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'b', label='Valifation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n```\n\n```\n<Figure size 640x480 with 1 Axes>\n\n```\n\n\n\n```python\nhistory_dict.keys()\n\n```\n\n\n\n```\ndict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n\n```\n\n\n\n```python\n#绘制训练精度和验证精度\nplt.clf()\nacc = history_dict['acc']\nval_acc = history_dict['val_acc']\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n```\n\n![png](Keras2/output_15_0.png)\n\n\n\n```python\nresults = model.evaluate(x_test, y_test)\nresults\n\n```\n\n```\n25000/25000 [==============================] - 7s 272us/step\n\n```\n\n\n\n\n\n```\n[0.768154475197792, 0.85032]\n\n```\n\n\n\n```python\n#预测评价正面的可能性\nmodel.predict(x_test)\n\n```\n\n\n\n```\narray([[0.00997098],\n       [0.9999999 ],\n       [0.971289  ],\n       ...,\n       [0.00219277],\n       [0.0054981 ],\n       [0.72482127]], dtype=float32)\n\n```\n\n\n\n![](Keras2/电影评级分类：二分类问题.pdf)","slug":"Keras2","published":1,"updated":"2019-02-18T11:20:27.539Z","comments":1,"layout":"post","link":"","_id":"cju3r7xh40000apndr9bepu33","content":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#加载IMDB数据集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.datasets <span class=\"keyword\">import</span> imdb</span><br><span class=\"line\">(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=<span class=\"number\">10000</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Using TensorFlow backend.</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[1,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 43,</span><br><span class=\"line\"> 530,</span><br><span class=\"line\"> 973,</span><br><span class=\"line\"> 1622,</span><br><span class=\"line\"> 1385,</span><br><span class=\"line\"> 65,</span><br><span class=\"line\"> 458,</span><br><span class=\"line\"> 4468,</span><br><span class=\"line\"> 66,</span><br><span class=\"line\"> 3941,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 173,</span><br><span class=\"line\"> 36,</span><br><span class=\"line\"> 256,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 25,</span><br><span class=\"line\"> 100,</span><br><span class=\"line\"> 43,</span><br><span class=\"line\"> 838,</span><br><span class=\"line\"> 112,</span><br><span class=\"line\"> 50,</span><br><span class=\"line\"> 670,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 9,</span><br><span class=\"line\"> 35,</span><br><span class=\"line\"> 480,</span><br><span class=\"line\"> 284,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 150,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 172,</span><br><span class=\"line\"> 112,</span><br><span class=\"line\"> 167,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 336,</span><br><span class=\"line\"> 385,</span><br><span class=\"line\"> 39,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 172,</span><br><span class=\"line\"> 4536,</span><br><span class=\"line\"> 1111,</span><br><span class=\"line\"> 17,</span><br><span class=\"line\"> 546,</span><br><span class=\"line\"> 38,</span><br><span class=\"line\"> 13,</span><br><span class=\"line\"> 447,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 192,</span><br><span class=\"line\"> 50,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 6,</span><br><span class=\"line\"> 147,</span><br><span class=\"line\"> 2025,</span><br><span class=\"line\"> 19,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 1920,</span><br><span class=\"line\"> 4613,</span><br><span class=\"line\"> 469,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 71,</span><br><span class=\"line\"> 87,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 43,</span><br><span class=\"line\"> 530,</span><br><span class=\"line\"> 38,</span><br><span class=\"line\"> 76,</span><br><span class=\"line\"> 15,</span><br><span class=\"line\"> 13,</span><br><span class=\"line\"> 1247,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 17,</span><br><span class=\"line\"> 515,</span><br><span class=\"line\"> 17,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 626,</span><br><span class=\"line\"> 18,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 62,</span><br><span class=\"line\"> 386,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 8,</span><br><span class=\"line\"> 316,</span><br><span class=\"line\"> 8,</span><br><span class=\"line\"> 106,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 2223,</span><br><span class=\"line\"> 5244,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 480,</span><br><span class=\"line\"> 66,</span><br><span class=\"line\"> 3785,</span><br><span class=\"line\"> 33,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 130,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 38,</span><br><span class=\"line\"> 619,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 25,</span><br><span class=\"line\"> 124,</span><br><span class=\"line\"> 51,</span><br><span class=\"line\"> 36,</span><br><span class=\"line\"> 135,</span><br><span class=\"line\"> 48,</span><br><span class=\"line\"> 25,</span><br><span class=\"line\"> 1415,</span><br><span class=\"line\"> 33,</span><br><span class=\"line\"> 6,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 215,</span><br><span class=\"line\"> 28,</span><br><span class=\"line\"> 77,</span><br><span class=\"line\"> 52,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 407,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 82,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 8,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 107,</span><br><span class=\"line\"> 117,</span><br><span class=\"line\"> 5952,</span><br><span class=\"line\"> 15,</span><br><span class=\"line\"> 256,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 7,</span><br><span class=\"line\"> 3766,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 723,</span><br><span class=\"line\"> 36,</span><br><span class=\"line\"> 71,</span><br><span class=\"line\"> 43,</span><br><span class=\"line\"> 530,</span><br><span class=\"line\"> 476,</span><br><span class=\"line\"> 26,</span><br><span class=\"line\"> 400,</span><br><span class=\"line\"> 317,</span><br><span class=\"line\"> 46,</span><br><span class=\"line\"> 7,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 1029,</span><br><span class=\"line\"> 13,</span><br><span class=\"line\"> 104,</span><br><span class=\"line\"> 88,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 381,</span><br><span class=\"line\"> 15,</span><br><span class=\"line\"> 297,</span><br><span class=\"line\"> 98,</span><br><span class=\"line\"> 32,</span><br><span class=\"line\"> 2071,</span><br><span class=\"line\"> 56,</span><br><span class=\"line\"> 26,</span><br><span class=\"line\"> 141,</span><br><span class=\"line\"> 6,</span><br><span class=\"line\"> 194,</span><br><span class=\"line\"> 7486,</span><br><span class=\"line\"> 18,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 226,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 21,</span><br><span class=\"line\"> 134,</span><br><span class=\"line\"> 476,</span><br><span class=\"line\"> 26,</span><br><span class=\"line\"> 480,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 144,</span><br><span class=\"line\"> 30,</span><br><span class=\"line\"> 5535,</span><br><span class=\"line\"> 18,</span><br><span class=\"line\"> 51,</span><br><span class=\"line\"> 36,</span><br><span class=\"line\"> 28,</span><br><span class=\"line\"> 224,</span><br><span class=\"line\"> 92,</span><br><span class=\"line\"> 25,</span><br><span class=\"line\"> 104,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 226,</span><br><span class=\"line\"> 65,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 38,</span><br><span class=\"line\"> 1334,</span><br><span class=\"line\"> 88,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 283,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 4472,</span><br><span class=\"line\"> 113,</span><br><span class=\"line\"> 103,</span><br><span class=\"line\"> 32,</span><br><span class=\"line\"> 15,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 5345,</span><br><span class=\"line\"> 19,</span><br><span class=\"line\"> 178,</span><br><span class=\"line\"> 32]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_labels</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array([1, 0, 0, ..., 0, 1, 0])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">max([max(sequence) <span class=\"keyword\">for</span> sequence <span class=\"keyword\">in</span> train_data])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">9999</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#索引解码成单词</span></span><br><span class=\"line\">word_index = imdb.get_word_index()</span><br><span class=\"line\">reverse_word_index = dict(</span><br><span class=\"line\">    [(value, key) <span class=\"keyword\">for</span> (key, value) <span class=\"keyword\">in</span> word_index.items()])</span><br><span class=\"line\">decoded_review = <span class=\"string\">' '</span>.join(</span><br><span class=\"line\">    [reverse_word_index.get(i - <span class=\"number\">3</span>, <span class=\"string\">'?'</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> train_data[<span class=\"number\">0</span>]])  <span class=\"comment\">#第一个评论</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">decoded_review</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;? this film was just brilliant casting location scenery story direction everyone&apos;s really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy&apos;s that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&apos;t you think the whole story was so lovely because it was true and was someone&apos;s life after all that was shared with us all&quot;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#数据向量化</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">vectorize_sequences</span><span class=\"params\">(sequences, dimension=<span class=\"number\">10000</span>)</span>:</span></span><br><span class=\"line\">    results= np.zeros((len(sequences), dimension))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, sequence <span class=\"keyword\">in</span> enumerate(sequences):</span><br><span class=\"line\">        results[i, sequence] = <span class=\"number\">1.</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> results</span><br><span class=\"line\"></span><br><span class=\"line\">x_train = vectorize_sequences(train_data)</span><br><span class=\"line\">x_test = vectorize_sequences(test_data)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x_train[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array([0., 1., 1., ..., 0., 0., 0.])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#标签向量化</span></span><br><span class=\"line\">y_train = np.asarray(train_labels).astype(<span class=\"string\">'float32'</span>)</span><br><span class=\"line\">y_test = np.asarray(test_labels).astype(<span class=\"string\">'float32'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#构建网络 模型定义</span></span><br><span class=\"line\"><span class=\"comment\">#激活函数relu 所有负值归0</span></span><br><span class=\"line\"><span class=\"comment\">#任意值“压缩”到[0, 1]区间内</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> models</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> layers</span><br><span class=\"line\">model = models.Sequential()</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">16</span>, activation=<span class=\"string\">'relu'</span>, input_shape=(<span class=\"number\">10000</span>,)))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">16</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">1</span>, activation=<span class=\"string\">'sigmoid'</span>))</span><br><span class=\"line\"><span class=\"comment\">#relu 负值归零 sigmoid 任意值压缩到[0, 1]区间内</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#损失函数 优化器 指标 编译模型</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\">model.compile(optimizer=<span class=\"string\">'rmsprop'</span>, loss=<span class=\"string\">'binary_crossentropy'</span>, metrics=[<span class=\"string\">'accuracy'</span>])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#从训练数据中留出验证集</span></span><br><span class=\"line\">x_val = x_train[:<span class=\"number\">10000</span>]</span><br><span class=\"line\">partial_x_train = x_train[<span class=\"number\">10000</span>:]</span><br><span class=\"line\"></span><br><span class=\"line\">y_val = y_train[:<span class=\"number\">10000</span>]</span><br><span class=\"line\">partial_y_train = y_train[<span class=\"number\">10000</span>:]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#训练模型</span></span><br><span class=\"line\">model.compile(optimizer=<span class=\"string\">'rmsprop'</span>, loss=<span class=\"string\">'binary_crossentropy'</span>, metrics=[<span class=\"string\">'acc'</span>])</span><br><span class=\"line\">history = model.fit(partial_x_train, partial_y_train, epochs=<span class=\"number\">20</span>, batch_size=<span class=\"number\">512</span>, validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Train on 15000 samples, validate on 10000 samples</span><br><span class=\"line\">Epoch 1/20</span><br><span class=\"line\">15000/15000 [==============================] - 6s 421us/step - loss: 0.5083 - acc: 0.7819 - val_loss: 0.3788 - val_acc: 0.8690</span><br><span class=\"line\">Epoch 2/20</span><br><span class=\"line\">15000/15000 [==============================] - 5s 311us/step - loss: 0.3001 - acc: 0.9048 - val_loss: 0.3000 - val_acc: 0.8901</span><br><span class=\"line\">Epoch 3/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 257us/step - loss: 0.2178 - acc: 0.9284 - val_loss: 0.3082 - val_acc: 0.8715</span><br><span class=\"line\">Epoch 4/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 221us/step - loss: 0.1750 - acc: 0.9435 - val_loss: 0.2838 - val_acc: 0.8839</span><br><span class=\"line\">Epoch 5/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 241us/step - loss: 0.1425 - acc: 0.9543 - val_loss: 0.2850 - val_acc: 0.8865</span><br><span class=\"line\">Epoch 6/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 222us/step - loss: 0.1149 - acc: 0.9652 - val_loss: 0.3163 - val_acc: 0.8773</span><br><span class=\"line\">Epoch 7/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 265us/step - loss: 0.0978 - acc: 0.9710 - val_loss: 0.3130 - val_acc: 0.8847</span><br><span class=\"line\">Epoch 8/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 231us/step - loss: 0.0807 - acc: 0.9765 - val_loss: 0.3861 - val_acc: 0.8653</span><br><span class=\"line\">Epoch 9/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 215us/step - loss: 0.0660 - acc: 0.9820 - val_loss: 0.3636 - val_acc: 0.8782</span><br><span class=\"line\">Epoch 10/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 254us/step - loss: 0.0555 - acc: 0.9852 - val_loss: 0.3845 - val_acc: 0.8790</span><br><span class=\"line\">Epoch 11/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 194us/step - loss: 0.0449 - acc: 0.9888 - val_loss: 0.4167 - val_acc: 0.8766</span><br><span class=\"line\">Epoch 12/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 247us/step - loss: 0.0385 - acc: 0.9913 - val_loss: 0.4511 - val_acc: 0.8700</span><br><span class=\"line\">Epoch 13/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 251us/step - loss: 0.0298 - acc: 0.9927 - val_loss: 0.4705 - val_acc: 0.8727</span><br><span class=\"line\">Epoch 14/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 259us/step - loss: 0.0244 - acc: 0.9949 - val_loss: 0.5029 - val_acc: 0.8723</span><br><span class=\"line\">Epoch 15/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 233us/step - loss: 0.0177 - acc: 0.9979 - val_loss: 0.5375 - val_acc: 0.8692</span><br><span class=\"line\">Epoch 16/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 239us/step - loss: 0.0170 - acc: 0.9967 - val_loss: 0.5728 - val_acc: 0.8702</span><br><span class=\"line\">Epoch 17/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 196us/step - loss: 0.0093 - acc: 0.9995 - val_loss: 0.6176 - val_acc: 0.8654</span><br><span class=\"line\">Epoch 18/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 224us/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.6386 - val_acc: 0.8669</span><br><span class=\"line\">Epoch 19/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 211us/step - loss: 0.0069 - acc: 0.9992 - val_loss: 0.7420 - val_acc: 0.8559</span><br><span class=\"line\">Epoch 20/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 238us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.6976 - val_acc: 0.8655</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#绘制训练损失和验证损失</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">history_dict = history.history</span><br><span class=\"line\">loss_values = history_dict[<span class=\"string\">'loss'</span>]</span><br><span class=\"line\">val_loss_values = history_dict[<span class=\"string\">'val_loss'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">epochs = range(<span class=\"number\">1</span>, len(loss_values) + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(epochs, loss_values, <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Training loss'</span>)</span><br><span class=\"line\">plt.plot(epochs, val_loss_values, <span class=\"string\">'b'</span>, label=<span class=\"string\">'Valifation loss'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Training and validation loss'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Loss'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;Figure size 640x480 with 1 Axes&gt;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">history_dict.keys()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dict_keys([&apos;val_loss&apos;, &apos;val_acc&apos;, &apos;loss&apos;, &apos;acc&apos;])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#绘制训练精度和验证精度</span></span><br><span class=\"line\">plt.clf()</span><br><span class=\"line\">acc = history_dict[<span class=\"string\">'acc'</span>]</span><br><span class=\"line\">val_acc = history_dict[<span class=\"string\">'val_acc'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(epochs, acc, <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Training acc'</span>)</span><br><span class=\"line\">plt.plot(epochs, val_acc, <span class=\"string\">'b'</span>, label=<span class=\"string\">'Validation acc'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Training and validation accuracy'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Accuracy'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras2/output_15_0.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">results = model.evaluate(x_test, y_test)</span><br><span class=\"line\">results</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">25000/25000 [==============================] - 7s 272us/step</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[0.768154475197792, 0.85032]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#预测评价正面的可能性</span></span><br><span class=\"line\">model.predict(x_test)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array([[0.00997098],</span><br><span class=\"line\">       [0.9999999 ],</span><br><span class=\"line\">       [0.971289  ],</span><br><span class=\"line\">       ...,</span><br><span class=\"line\">       [0.00219277],</span><br><span class=\"line\">       [0.0054981 ],</span><br><span class=\"line\">       [0.72482127]], dtype=float32)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras2/电影评级分类：二分类问题.pdf\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#加载IMDB数据集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.datasets <span class=\"keyword\">import</span> imdb</span><br><span class=\"line\">(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=<span class=\"number\">10000</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Using TensorFlow backend.</span><br></pre></td></tr></table></figure>","more":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[1,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 43,</span><br><span class=\"line\"> 530,</span><br><span class=\"line\"> 973,</span><br><span class=\"line\"> 1622,</span><br><span class=\"line\"> 1385,</span><br><span class=\"line\"> 65,</span><br><span class=\"line\"> 458,</span><br><span class=\"line\"> 4468,</span><br><span class=\"line\"> 66,</span><br><span class=\"line\"> 3941,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 173,</span><br><span class=\"line\"> 36,</span><br><span class=\"line\"> 256,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 25,</span><br><span class=\"line\"> 100,</span><br><span class=\"line\"> 43,</span><br><span class=\"line\"> 838,</span><br><span class=\"line\"> 112,</span><br><span class=\"line\"> 50,</span><br><span class=\"line\"> 670,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 9,</span><br><span class=\"line\"> 35,</span><br><span class=\"line\"> 480,</span><br><span class=\"line\"> 284,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 150,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 172,</span><br><span class=\"line\"> 112,</span><br><span class=\"line\"> 167,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 336,</span><br><span class=\"line\"> 385,</span><br><span class=\"line\"> 39,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 172,</span><br><span class=\"line\"> 4536,</span><br><span class=\"line\"> 1111,</span><br><span class=\"line\"> 17,</span><br><span class=\"line\"> 546,</span><br><span class=\"line\"> 38,</span><br><span class=\"line\"> 13,</span><br><span class=\"line\"> 447,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 192,</span><br><span class=\"line\"> 50,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 6,</span><br><span class=\"line\"> 147,</span><br><span class=\"line\"> 2025,</span><br><span class=\"line\"> 19,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 1920,</span><br><span class=\"line\"> 4613,</span><br><span class=\"line\"> 469,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 71,</span><br><span class=\"line\"> 87,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 43,</span><br><span class=\"line\"> 530,</span><br><span class=\"line\"> 38,</span><br><span class=\"line\"> 76,</span><br><span class=\"line\"> 15,</span><br><span class=\"line\"> 13,</span><br><span class=\"line\"> 1247,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 17,</span><br><span class=\"line\"> 515,</span><br><span class=\"line\"> 17,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 626,</span><br><span class=\"line\"> 18,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 62,</span><br><span class=\"line\"> 386,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 8,</span><br><span class=\"line\"> 316,</span><br><span class=\"line\"> 8,</span><br><span class=\"line\"> 106,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 2223,</span><br><span class=\"line\"> 5244,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 480,</span><br><span class=\"line\"> 66,</span><br><span class=\"line\"> 3785,</span><br><span class=\"line\"> 33,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 130,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 38,</span><br><span class=\"line\"> 619,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 25,</span><br><span class=\"line\"> 124,</span><br><span class=\"line\"> 51,</span><br><span class=\"line\"> 36,</span><br><span class=\"line\"> 135,</span><br><span class=\"line\"> 48,</span><br><span class=\"line\"> 25,</span><br><span class=\"line\"> 1415,</span><br><span class=\"line\"> 33,</span><br><span class=\"line\"> 6,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 215,</span><br><span class=\"line\"> 28,</span><br><span class=\"line\"> 77,</span><br><span class=\"line\"> 52,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 407,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 82,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 8,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 107,</span><br><span class=\"line\"> 117,</span><br><span class=\"line\"> 5952,</span><br><span class=\"line\"> 15,</span><br><span class=\"line\"> 256,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 7,</span><br><span class=\"line\"> 3766,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 723,</span><br><span class=\"line\"> 36,</span><br><span class=\"line\"> 71,</span><br><span class=\"line\"> 43,</span><br><span class=\"line\"> 530,</span><br><span class=\"line\"> 476,</span><br><span class=\"line\"> 26,</span><br><span class=\"line\"> 400,</span><br><span class=\"line\"> 317,</span><br><span class=\"line\"> 46,</span><br><span class=\"line\"> 7,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 2,</span><br><span class=\"line\"> 1029,</span><br><span class=\"line\"> 13,</span><br><span class=\"line\"> 104,</span><br><span class=\"line\"> 88,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 381,</span><br><span class=\"line\"> 15,</span><br><span class=\"line\"> 297,</span><br><span class=\"line\"> 98,</span><br><span class=\"line\"> 32,</span><br><span class=\"line\"> 2071,</span><br><span class=\"line\"> 56,</span><br><span class=\"line\"> 26,</span><br><span class=\"line\"> 141,</span><br><span class=\"line\"> 6,</span><br><span class=\"line\"> 194,</span><br><span class=\"line\"> 7486,</span><br><span class=\"line\"> 18,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 226,</span><br><span class=\"line\"> 22,</span><br><span class=\"line\"> 21,</span><br><span class=\"line\"> 134,</span><br><span class=\"line\"> 476,</span><br><span class=\"line\"> 26,</span><br><span class=\"line\"> 480,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 144,</span><br><span class=\"line\"> 30,</span><br><span class=\"line\"> 5535,</span><br><span class=\"line\"> 18,</span><br><span class=\"line\"> 51,</span><br><span class=\"line\"> 36,</span><br><span class=\"line\"> 28,</span><br><span class=\"line\"> 224,</span><br><span class=\"line\"> 92,</span><br><span class=\"line\"> 25,</span><br><span class=\"line\"> 104,</span><br><span class=\"line\"> 4,</span><br><span class=\"line\"> 226,</span><br><span class=\"line\"> 65,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 38,</span><br><span class=\"line\"> 1334,</span><br><span class=\"line\"> 88,</span><br><span class=\"line\"> 12,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 283,</span><br><span class=\"line\"> 5,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 4472,</span><br><span class=\"line\"> 113,</span><br><span class=\"line\"> 103,</span><br><span class=\"line\"> 32,</span><br><span class=\"line\"> 15,</span><br><span class=\"line\"> 16,</span><br><span class=\"line\"> 5345,</span><br><span class=\"line\"> 19,</span><br><span class=\"line\"> 178,</span><br><span class=\"line\"> 32]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_labels</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array([1, 0, 0, ..., 0, 1, 0])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">max([max(sequence) <span class=\"keyword\">for</span> sequence <span class=\"keyword\">in</span> train_data])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">9999</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#索引解码成单词</span></span><br><span class=\"line\">word_index = imdb.get_word_index()</span><br><span class=\"line\">reverse_word_index = dict(</span><br><span class=\"line\">    [(value, key) <span class=\"keyword\">for</span> (key, value) <span class=\"keyword\">in</span> word_index.items()])</span><br><span class=\"line\">decoded_review = <span class=\"string\">' '</span>.join(</span><br><span class=\"line\">    [reverse_word_index.get(i - <span class=\"number\">3</span>, <span class=\"string\">'?'</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> train_data[<span class=\"number\">0</span>]])  <span class=\"comment\">#第一个评论</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">decoded_review</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&quot;? this film was just brilliant casting location scenery story direction everyone&apos;s really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy&apos;s that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&apos;t you think the whole story was so lovely because it was true and was someone&apos;s life after all that was shared with us all&quot;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#数据向量化</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">vectorize_sequences</span><span class=\"params\">(sequences, dimension=<span class=\"number\">10000</span>)</span>:</span></span><br><span class=\"line\">    results= np.zeros((len(sequences), dimension))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, sequence <span class=\"keyword\">in</span> enumerate(sequences):</span><br><span class=\"line\">        results[i, sequence] = <span class=\"number\">1.</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> results</span><br><span class=\"line\"></span><br><span class=\"line\">x_train = vectorize_sequences(train_data)</span><br><span class=\"line\">x_test = vectorize_sequences(test_data)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x_train[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array([0., 1., 1., ..., 0., 0., 0.])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#标签向量化</span></span><br><span class=\"line\">y_train = np.asarray(train_labels).astype(<span class=\"string\">'float32'</span>)</span><br><span class=\"line\">y_test = np.asarray(test_labels).astype(<span class=\"string\">'float32'</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#构建网络 模型定义</span></span><br><span class=\"line\"><span class=\"comment\">#激活函数relu 所有负值归0</span></span><br><span class=\"line\"><span class=\"comment\">#任意值“压缩”到[0, 1]区间内</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> models</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> layers</span><br><span class=\"line\">model = models.Sequential()</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">16</span>, activation=<span class=\"string\">'relu'</span>, input_shape=(<span class=\"number\">10000</span>,)))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">16</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">1</span>, activation=<span class=\"string\">'sigmoid'</span>))</span><br><span class=\"line\"><span class=\"comment\">#relu 负值归零 sigmoid 任意值压缩到[0, 1]区间内</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#损失函数 优化器 指标 编译模型</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\">model.compile(optimizer=<span class=\"string\">'rmsprop'</span>, loss=<span class=\"string\">'binary_crossentropy'</span>, metrics=[<span class=\"string\">'accuracy'</span>])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#从训练数据中留出验证集</span></span><br><span class=\"line\">x_val = x_train[:<span class=\"number\">10000</span>]</span><br><span class=\"line\">partial_x_train = x_train[<span class=\"number\">10000</span>:]</span><br><span class=\"line\"></span><br><span class=\"line\">y_val = y_train[:<span class=\"number\">10000</span>]</span><br><span class=\"line\">partial_y_train = y_train[<span class=\"number\">10000</span>:]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#训练模型</span></span><br><span class=\"line\">model.compile(optimizer=<span class=\"string\">'rmsprop'</span>, loss=<span class=\"string\">'binary_crossentropy'</span>, metrics=[<span class=\"string\">'acc'</span>])</span><br><span class=\"line\">history = model.fit(partial_x_train, partial_y_train, epochs=<span class=\"number\">20</span>, batch_size=<span class=\"number\">512</span>, validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Train on 15000 samples, validate on 10000 samples</span><br><span class=\"line\">Epoch 1/20</span><br><span class=\"line\">15000/15000 [==============================] - 6s 421us/step - loss: 0.5083 - acc: 0.7819 - val_loss: 0.3788 - val_acc: 0.8690</span><br><span class=\"line\">Epoch 2/20</span><br><span class=\"line\">15000/15000 [==============================] - 5s 311us/step - loss: 0.3001 - acc: 0.9048 - val_loss: 0.3000 - val_acc: 0.8901</span><br><span class=\"line\">Epoch 3/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 257us/step - loss: 0.2178 - acc: 0.9284 - val_loss: 0.3082 - val_acc: 0.8715</span><br><span class=\"line\">Epoch 4/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 221us/step - loss: 0.1750 - acc: 0.9435 - val_loss: 0.2838 - val_acc: 0.8839</span><br><span class=\"line\">Epoch 5/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 241us/step - loss: 0.1425 - acc: 0.9543 - val_loss: 0.2850 - val_acc: 0.8865</span><br><span class=\"line\">Epoch 6/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 222us/step - loss: 0.1149 - acc: 0.9652 - val_loss: 0.3163 - val_acc: 0.8773</span><br><span class=\"line\">Epoch 7/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 265us/step - loss: 0.0978 - acc: 0.9710 - val_loss: 0.3130 - val_acc: 0.8847</span><br><span class=\"line\">Epoch 8/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 231us/step - loss: 0.0807 - acc: 0.9765 - val_loss: 0.3861 - val_acc: 0.8653</span><br><span class=\"line\">Epoch 9/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 215us/step - loss: 0.0660 - acc: 0.9820 - val_loss: 0.3636 - val_acc: 0.8782</span><br><span class=\"line\">Epoch 10/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 254us/step - loss: 0.0555 - acc: 0.9852 - val_loss: 0.3845 - val_acc: 0.8790</span><br><span class=\"line\">Epoch 11/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 194us/step - loss: 0.0449 - acc: 0.9888 - val_loss: 0.4167 - val_acc: 0.8766</span><br><span class=\"line\">Epoch 12/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 247us/step - loss: 0.0385 - acc: 0.9913 - val_loss: 0.4511 - val_acc: 0.8700</span><br><span class=\"line\">Epoch 13/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 251us/step - loss: 0.0298 - acc: 0.9927 - val_loss: 0.4705 - val_acc: 0.8727</span><br><span class=\"line\">Epoch 14/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 259us/step - loss: 0.0244 - acc: 0.9949 - val_loss: 0.5029 - val_acc: 0.8723</span><br><span class=\"line\">Epoch 15/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 233us/step - loss: 0.0177 - acc: 0.9979 - val_loss: 0.5375 - val_acc: 0.8692</span><br><span class=\"line\">Epoch 16/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 239us/step - loss: 0.0170 - acc: 0.9967 - val_loss: 0.5728 - val_acc: 0.8702</span><br><span class=\"line\">Epoch 17/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 196us/step - loss: 0.0093 - acc: 0.9995 - val_loss: 0.6176 - val_acc: 0.8654</span><br><span class=\"line\">Epoch 18/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 224us/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.6386 - val_acc: 0.8669</span><br><span class=\"line\">Epoch 19/20</span><br><span class=\"line\">15000/15000 [==============================] - 3s 211us/step - loss: 0.0069 - acc: 0.9992 - val_loss: 0.7420 - val_acc: 0.8559</span><br><span class=\"line\">Epoch 20/20</span><br><span class=\"line\">15000/15000 [==============================] - 4s 238us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.6976 - val_acc: 0.8655</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#绘制训练损失和验证损失</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">history_dict = history.history</span><br><span class=\"line\">loss_values = history_dict[<span class=\"string\">'loss'</span>]</span><br><span class=\"line\">val_loss_values = history_dict[<span class=\"string\">'val_loss'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">epochs = range(<span class=\"number\">1</span>, len(loss_values) + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(epochs, loss_values, <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Training loss'</span>)</span><br><span class=\"line\">plt.plot(epochs, val_loss_values, <span class=\"string\">'b'</span>, label=<span class=\"string\">'Valifation loss'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Training and validation loss'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Loss'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;Figure size 640x480 with 1 Axes&gt;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">history_dict.keys()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dict_keys([&apos;val_loss&apos;, &apos;val_acc&apos;, &apos;loss&apos;, &apos;acc&apos;])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#绘制训练精度和验证精度</span></span><br><span class=\"line\">plt.clf()</span><br><span class=\"line\">acc = history_dict[<span class=\"string\">'acc'</span>]</span><br><span class=\"line\">val_acc = history_dict[<span class=\"string\">'val_acc'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(epochs, acc, <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Training acc'</span>)</span><br><span class=\"line\">plt.plot(epochs, val_acc, <span class=\"string\">'b'</span>, label=<span class=\"string\">'Validation acc'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Training and validation accuracy'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Accuracy'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras2/output_15_0.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">results = model.evaluate(x_test, y_test)</span><br><span class=\"line\">results</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">25000/25000 [==============================] - 7s 272us/step</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[0.768154475197792, 0.85032]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#预测评价正面的可能性</span></span><br><span class=\"line\">model.predict(x_test)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array([[0.00997098],</span><br><span class=\"line\">       [0.9999999 ],</span><br><span class=\"line\">       [0.971289  ],</span><br><span class=\"line\">       ...,</span><br><span class=\"line\">       [0.00219277],</span><br><span class=\"line\">       [0.0054981 ],</span><br><span class=\"line\">       [0.72482127]], dtype=float32)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras2/电影评级分类：二分类问题.pdf\" alt=\"\"></p>"},{"title":"Keras学习（一）：Mac OS下安装基于TensorFlow的Keras","date":"2019-01-24T01:20:32.000Z","photos":["1.png","https://images.33dot3.xyz/hello_world.jpg"],"_content":"\n操作系统：macOs High Sierra 10.13.6\n\n## 1. TensorFlow安装\n\n**必备：Python**\n\n采用pip方式安装TensorFlow，命令如下：\n\n```\nsudo pip install tensorflow\n```\n\n在输入该命令过程中遇到问题如下：（如无遇到可跳过）\n\n```\nCould not find a version that satisfies the requirement tensorflow ......\n```\n\n原因是**python版本问题**：最新的anaconda中python版本已经更新到python3.7，而tensorflow只支持到python3.6。\n\n<!--more-->\n\n在anaconda官网中给出了三种解决方案： \n\n![](Keras1/install-python-3-6.jpg)\n\n选择第二种方案，在命令行输入如下命令：\n\n```\nsudo conda install python=3.6\n```\n\n![](Keras1/install-python-3-6-2.png)\n\npython3.6安装完成。再如上输入命令，tensorflow安装完成。\n\n## 2. Keras安装\n\n采用pip方式安装Keras，命令如下：\n\n```\nsudo pip install keras\n```\n\n![](Keras1/install-keras.png)\n\nKeras安装完成。\n\n## 3. 实例测试\n\n![](Keras1/keras-test.png)\n\n","source":"_posts/Keras1.md","raw":"---\ntitle: Keras学习（一）：Mac OS下安装基于TensorFlow的Keras\ndate: 2019-01-24 09:20:32\ntags:\n    - Keras\ncategories:\n    - Notes\nphotos:\n    - 1.png\n    - https://images.33dot3.xyz/hello_world.jpg\n---\n\n操作系统：macOs High Sierra 10.13.6\n\n## 1. TensorFlow安装\n\n**必备：Python**\n\n采用pip方式安装TensorFlow，命令如下：\n\n```\nsudo pip install tensorflow\n```\n\n在输入该命令过程中遇到问题如下：（如无遇到可跳过）\n\n```\nCould not find a version that satisfies the requirement tensorflow ......\n```\n\n原因是**python版本问题**：最新的anaconda中python版本已经更新到python3.7，而tensorflow只支持到python3.6。\n\n<!--more-->\n\n在anaconda官网中给出了三种解决方案： \n\n![](Keras1/install-python-3-6.jpg)\n\n选择第二种方案，在命令行输入如下命令：\n\n```\nsudo conda install python=3.6\n```\n\n![](Keras1/install-python-3-6-2.png)\n\npython3.6安装完成。再如上输入命令，tensorflow安装完成。\n\n## 2. Keras安装\n\n采用pip方式安装Keras，命令如下：\n\n```\nsudo pip install keras\n```\n\n![](Keras1/install-keras.png)\n\nKeras安装完成。\n\n## 3. 实例测试\n\n![](Keras1/keras-test.png)\n\n","slug":"Keras1","published":1,"updated":"2019-01-25T04:23:35.878Z","comments":1,"layout":"post","link":"","_id":"cju3r7xha0002apndr8450cdt","content":"<p>操作系统：macOs High Sierra 10.13.6</p>\n<h2 id=\"1-TensorFlow安装\"><a href=\"#1-TensorFlow安装\" class=\"headerlink\" title=\"1. TensorFlow安装\"></a>1. TensorFlow安装</h2><p><strong>必备：Python</strong></p>\n<p>采用pip方式安装TensorFlow，命令如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip install tensorflow</span><br></pre></td></tr></table></figure>\n<p>在输入该命令过程中遇到问题如下：（如无遇到可跳过）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Could not find a version that satisfies the requirement tensorflow ......</span><br></pre></td></tr></table></figure>\n<p>原因是<strong>python版本问题</strong>：最新的anaconda中python版本已经更新到python3.7，而tensorflow只支持到python3.6。</p>\n<a id=\"more\"></a>\n<p>在anaconda官网中给出了三种解决方案： </p>\n<p><img src=\"/2019/01/24/Keras1/install-python-3-6.jpg\" alt=\"\"></p>\n<p>选择第二种方案，在命令行输入如下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo conda install python=3.6</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/24/Keras1/install-python-3-6-2.png\" alt=\"\"></p>\n<p>python3.6安装完成。再如上输入命令，tensorflow安装完成。</p>\n<h2 id=\"2-Keras安装\"><a href=\"#2-Keras安装\" class=\"headerlink\" title=\"2. Keras安装\"></a>2. Keras安装</h2><p>采用pip方式安装Keras，命令如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip install keras</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/24/Keras1/install-keras.png\" alt=\"\"></p>\n<p>Keras安装完成。</p>\n<h2 id=\"3-实例测试\"><a href=\"#3-实例测试\" class=\"headerlink\" title=\"3. 实例测试\"></a>3. 实例测试</h2><p><img src=\"/2019/01/24/Keras1/keras-test.png\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"<p>操作系统：macOs High Sierra 10.13.6</p>\n<h2 id=\"1-TensorFlow安装\"><a href=\"#1-TensorFlow安装\" class=\"headerlink\" title=\"1. TensorFlow安装\"></a>1. TensorFlow安装</h2><p><strong>必备：Python</strong></p>\n<p>采用pip方式安装TensorFlow，命令如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip install tensorflow</span><br></pre></td></tr></table></figure>\n<p>在输入该命令过程中遇到问题如下：（如无遇到可跳过）</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Could not find a version that satisfies the requirement tensorflow ......</span><br></pre></td></tr></table></figure>\n<p>原因是<strong>python版本问题</strong>：最新的anaconda中python版本已经更新到python3.7，而tensorflow只支持到python3.6。</p>","more":"<p>在anaconda官网中给出了三种解决方案： </p>\n<p><img src=\"/2019/01/24/Keras1/install-python-3-6.jpg\" alt=\"\"></p>\n<p>选择第二种方案，在命令行输入如下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo conda install python=3.6</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/24/Keras1/install-python-3-6-2.png\" alt=\"\"></p>\n<p>python3.6安装完成。再如上输入命令，tensorflow安装完成。</p>\n<h2 id=\"2-Keras安装\"><a href=\"#2-Keras安装\" class=\"headerlink\" title=\"2. Keras安装\"></a>2. Keras安装</h2><p>采用pip方式安装Keras，命令如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip install keras</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/24/Keras1/install-keras.png\" alt=\"\"></p>\n<p>Keras安装完成。</p>\n<h2 id=\"3-实例测试\"><a href=\"#3-实例测试\" class=\"headerlink\" title=\"3. 实例测试\"></a>3. 实例测试</h2><p><img src=\"/2019/01/24/Keras1/keras-test.png\" alt=\"\"></p>"},{"title":"KERAS学习（四）：预测房价-回归问题","date":"2019-01-28T12:08:52.000Z","photos":["output_11_0.png"],"_content":"\n```python\n#加载波士顿房价数据\nfrom keras.datasets import boston_housing\n(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n```\n\n```\nUsing TensorFlow backend.\n```\n\n```\nDownloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n57344/57026 [==============================] - 1s 10us/step\n```\n\n<!-- more -->\n\n```python\ntrain_data.shape\n```\n\n\n\n```\n(404, 13)\n```\n\n\n\n```python\ntest_data.shape\n```\n\n\n\n```\n(102, 13)\n```\n\n\n\n```python\ntrain_targets\n```\n\n\n\n```\narray([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])\n\n```\n\n\n\n```python\n#数据特征标准化  （特征-平均值）/标准差\nmean = train_data.mean(axis=0)   #特征平均值\ntrain_data -= mean\nstd = train_data.std(axis=0)   #标准差\ntrain_data /= std\n\ntest_data -= mean\ntest_data /= std\n\n```\n\n```python\n#构建网络 模型定义\nfrom keras import models\nfrom keras import layers\n\n#需要将同一个模型多次实例化，所以用一个函数来构建模型\n#MSE损失函数（mean squared error）：均方误差，预测值与目标值之差的平方\n#MAE指标（mean absolute error）：平均绝对误差，预测值与目标值之差的绝对值\ndef build_model():\n    model = models.Sequential()\n    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1], )))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(1))   #没有激活，线性层\n    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n    return model\n\n```\n\n```python\n#K折交叉验证\nimport numpy as np\n\nk = 4\nnum_val_samples = len(train_data) // k\nnum_epochs = 100   #训练100轮次\nall_scores = []\n\nfor i in range(k):\n    print('processing fold #', i)\n    #准备验证数据：第k个分区的数据\n    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n    #准备训练数据：其他所有分区的数据\n    partial_train_data = np.concatenate(\n        [train_data[:i * num_val_samples],\n         train_data[(i + 1) * num_val_samples: ]],\n        axis=0\n    )\n    partial_train_targets = np.concatenate(\n        [train_targets[:i * num_val_samples],\n         train_targets[(i + 1) * num_val_samples: ]],\n        axis=0\n    )\n    #构建Keras模型（已编译）\n    model = build_model()\n    #训练模型（静默模式，verbose=0）\n    model.fit(partial_train_data, partial_train_targets,\n             epochs=num_epochs, batch_size=1, verbose=0)\n    在验证数据上评估模型\n    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n    all_scores.append(val_mae)\n\n```\n\n```\nprocessing fold # 0\nprocessing fold # 1\nprocessing fold # 2\nprocessing fold # 3\n\n```\n\n\n\n```python\nall_scores\n\n```\n\n\n\n```\n[1.953495462342064, 2.7316349308089456, 2.4950007542525188, 2.304117675464932]\n\n```\n\n\n\n```python\nnp.mean(all_scores)\n#差别很大\n\n```\n\n\n\n```\n2.371062205717115\n\n```\n\n\n\n```python\n#重新训练 500轮次\n#保存每折的验证结果\nnum_epochs = 500\nall_mae_histories = []\nfor i in range(k):\n    print('processing fold #', i)\n    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n    \n    partial_train_data = np.concatenate(\n    [train_data[:i * num_val_samples],\n     train_data[(i + 1) * num_val_samples: ]],\n    axis=0\n    )\n    \n    partial_train_targets = np.concatenate(\n    [train_targets[:i * num_val_samples],\n     train_targets[(i + 1) * num_val_samples: ]],\n    axis=0\n    )\n    \n    model = build_model()\n    history = model.fit(partial_train_data, partial_train_targets,\n                               validation_data=(val_data, val_targets),\n                               epochs=num_epochs, batch_size=1, verbose=0)\n    mae_history = history.history['val_mean_absolute_error']\n    all_mae_histories.append(mae_history)\n\n```\n\n```\nprocessing fold # 0\nprocessing fold # 1\nprocessing fold # 2\nprocessing fold # 3\n\n```\n\n\n\n```python\n#计算所有轮次中的K折验证分数平均值\naverage_mae_history = [\n    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n\n```\n\n```python\n#绘制验证分数 纵轴范围较大，数据方差相对较大，难以看清规律，重新绘制\nimport matplotlib.pyplot as plt\n\nplt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\nplt.xlabel('Epochs')\nplt.ylabel('Validation MAE')\nplt.show()\n\n```\n\n![png](Keras4/output_11_0.png)\n\n\n\n```python\n#重新绘制：删除前10个数据点，将每个数据点替换为前面数据点的指数移动平均值\ndef smooth_curve(points, factor=0.9):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points\n\nsmooth_mae_history = smooth_curve(average_mae_history[10: ])\n\nplt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\nplt.xlabel('Epochs')\nplt.ylabel('Validation MAE')\nplt.show()\n\n```\n\n![png](Keras4/output_12_0.png)\n\n\n\n```python\n#上一轮出现过拟合\n#训练最终模型\nmodel = build_model()\nmodel.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\ntest_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n```\n\n```\n102/102 [==============================] - 0s 2ms/step\n```\n\n\n\n```python\n#最终结果\ntest_mae_score\n```\n\n\n\n```\n2.577465954948874\n```\n\n\n\n```python\ntest_mse_score\n```\n\n\n\n```\n16.48435390696806\n```\n\n\n\n```python\n\n```","source":"_posts/Keras4.md","raw":"---\ntitle: KERAS学习（四）：预测房价-回归问题\ndate: 2019-01-28 20:08:52\ntags:\n    - Keras\ncategories:\n    - Notes\nphotos:\n    - output_11_0.png\n---\n\n```python\n#加载波士顿房价数据\nfrom keras.datasets import boston_housing\n(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n```\n\n```\nUsing TensorFlow backend.\n```\n\n```\nDownloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n57344/57026 [==============================] - 1s 10us/step\n```\n\n<!-- more -->\n\n```python\ntrain_data.shape\n```\n\n\n\n```\n(404, 13)\n```\n\n\n\n```python\ntest_data.shape\n```\n\n\n\n```\n(102, 13)\n```\n\n\n\n```python\ntrain_targets\n```\n\n\n\n```\narray([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])\n\n```\n\n\n\n```python\n#数据特征标准化  （特征-平均值）/标准差\nmean = train_data.mean(axis=0)   #特征平均值\ntrain_data -= mean\nstd = train_data.std(axis=0)   #标准差\ntrain_data /= std\n\ntest_data -= mean\ntest_data /= std\n\n```\n\n```python\n#构建网络 模型定义\nfrom keras import models\nfrom keras import layers\n\n#需要将同一个模型多次实例化，所以用一个函数来构建模型\n#MSE损失函数（mean squared error）：均方误差，预测值与目标值之差的平方\n#MAE指标（mean absolute error）：平均绝对误差，预测值与目标值之差的绝对值\ndef build_model():\n    model = models.Sequential()\n    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1], )))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(1))   #没有激活，线性层\n    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n    return model\n\n```\n\n```python\n#K折交叉验证\nimport numpy as np\n\nk = 4\nnum_val_samples = len(train_data) // k\nnum_epochs = 100   #训练100轮次\nall_scores = []\n\nfor i in range(k):\n    print('processing fold #', i)\n    #准备验证数据：第k个分区的数据\n    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n    #准备训练数据：其他所有分区的数据\n    partial_train_data = np.concatenate(\n        [train_data[:i * num_val_samples],\n         train_data[(i + 1) * num_val_samples: ]],\n        axis=0\n    )\n    partial_train_targets = np.concatenate(\n        [train_targets[:i * num_val_samples],\n         train_targets[(i + 1) * num_val_samples: ]],\n        axis=0\n    )\n    #构建Keras模型（已编译）\n    model = build_model()\n    #训练模型（静默模式，verbose=0）\n    model.fit(partial_train_data, partial_train_targets,\n             epochs=num_epochs, batch_size=1, verbose=0)\n    在验证数据上评估模型\n    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n    all_scores.append(val_mae)\n\n```\n\n```\nprocessing fold # 0\nprocessing fold # 1\nprocessing fold # 2\nprocessing fold # 3\n\n```\n\n\n\n```python\nall_scores\n\n```\n\n\n\n```\n[1.953495462342064, 2.7316349308089456, 2.4950007542525188, 2.304117675464932]\n\n```\n\n\n\n```python\nnp.mean(all_scores)\n#差别很大\n\n```\n\n\n\n```\n2.371062205717115\n\n```\n\n\n\n```python\n#重新训练 500轮次\n#保存每折的验证结果\nnum_epochs = 500\nall_mae_histories = []\nfor i in range(k):\n    print('processing fold #', i)\n    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n    \n    partial_train_data = np.concatenate(\n    [train_data[:i * num_val_samples],\n     train_data[(i + 1) * num_val_samples: ]],\n    axis=0\n    )\n    \n    partial_train_targets = np.concatenate(\n    [train_targets[:i * num_val_samples],\n     train_targets[(i + 1) * num_val_samples: ]],\n    axis=0\n    )\n    \n    model = build_model()\n    history = model.fit(partial_train_data, partial_train_targets,\n                               validation_data=(val_data, val_targets),\n                               epochs=num_epochs, batch_size=1, verbose=0)\n    mae_history = history.history['val_mean_absolute_error']\n    all_mae_histories.append(mae_history)\n\n```\n\n```\nprocessing fold # 0\nprocessing fold # 1\nprocessing fold # 2\nprocessing fold # 3\n\n```\n\n\n\n```python\n#计算所有轮次中的K折验证分数平均值\naverage_mae_history = [\n    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n\n```\n\n```python\n#绘制验证分数 纵轴范围较大，数据方差相对较大，难以看清规律，重新绘制\nimport matplotlib.pyplot as plt\n\nplt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\nplt.xlabel('Epochs')\nplt.ylabel('Validation MAE')\nplt.show()\n\n```\n\n![png](Keras4/output_11_0.png)\n\n\n\n```python\n#重新绘制：删除前10个数据点，将每个数据点替换为前面数据点的指数移动平均值\ndef smooth_curve(points, factor=0.9):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points\n\nsmooth_mae_history = smooth_curve(average_mae_history[10: ])\n\nplt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\nplt.xlabel('Epochs')\nplt.ylabel('Validation MAE')\nplt.show()\n\n```\n\n![png](Keras4/output_12_0.png)\n\n\n\n```python\n#上一轮出现过拟合\n#训练最终模型\nmodel = build_model()\nmodel.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\ntest_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n```\n\n```\n102/102 [==============================] - 0s 2ms/step\n```\n\n\n\n```python\n#最终结果\ntest_mae_score\n```\n\n\n\n```\n2.577465954948874\n```\n\n\n\n```python\ntest_mse_score\n```\n\n\n\n```\n16.48435390696806\n```\n\n\n\n```python\n\n```","slug":"Keras4","published":1,"updated":"2019-01-28T12:16:36.333Z","comments":1,"layout":"post","link":"","_id":"cju3r7xhg0006apnddn1kso7m","content":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#加载波士顿房价数据</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.datasets <span class=\"keyword\">import</span> boston_housing</span><br><span class=\"line\">(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Using TensorFlow backend.</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz</span><br><span class=\"line\">57344/57026 [==============================] - 1s 10us/step</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data.shape</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(404, 13)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test_data.shape</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(102, 13)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_targets</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,</span><br><span class=\"line\">       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,</span><br><span class=\"line\">       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,</span><br><span class=\"line\">       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,</span><br><span class=\"line\">       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,</span><br><span class=\"line\">       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,</span><br><span class=\"line\">       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,</span><br><span class=\"line\">       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,</span><br><span class=\"line\">       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,</span><br><span class=\"line\">       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,</span><br><span class=\"line\">       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,</span><br><span class=\"line\">       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,</span><br><span class=\"line\">       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,</span><br><span class=\"line\">       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,</span><br><span class=\"line\">       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,</span><br><span class=\"line\">       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,</span><br><span class=\"line\">        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,</span><br><span class=\"line\">       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,</span><br><span class=\"line\">       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,</span><br><span class=\"line\">       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,</span><br><span class=\"line\">       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,</span><br><span class=\"line\">       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,</span><br><span class=\"line\">       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,</span><br><span class=\"line\">       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,</span><br><span class=\"line\">       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,</span><br><span class=\"line\">       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,</span><br><span class=\"line\">        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,</span><br><span class=\"line\">        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,</span><br><span class=\"line\">       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,</span><br><span class=\"line\">       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,</span><br><span class=\"line\">       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,</span><br><span class=\"line\">       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,</span><br><span class=\"line\">       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,</span><br><span class=\"line\">       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,</span><br><span class=\"line\">       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,</span><br><span class=\"line\">       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,</span><br><span class=\"line\">       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#数据特征标准化  （特征-平均值）/标准差</span></span><br><span class=\"line\">mean = train_data.mean(axis=<span class=\"number\">0</span>)   <span class=\"comment\">#特征平均值</span></span><br><span class=\"line\">train_data -= mean</span><br><span class=\"line\">std = train_data.std(axis=<span class=\"number\">0</span>)   <span class=\"comment\">#标准差</span></span><br><span class=\"line\">train_data /= std</span><br><span class=\"line\"></span><br><span class=\"line\">test_data -= mean</span><br><span class=\"line\">test_data /= std</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#构建网络 模型定义</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> models</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> layers</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#需要将同一个模型多次实例化，所以用一个函数来构建模型</span></span><br><span class=\"line\"><span class=\"comment\">#MSE损失函数（mean squared error）：均方误差，预测值与目标值之差的平方</span></span><br><span class=\"line\"><span class=\"comment\">#MAE指标（mean absolute error）：平均绝对误差，预测值与目标值之差的绝对值</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">build_model</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    model = models.Sequential()</span><br><span class=\"line\">    model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>, input_shape=(train_data.shape[<span class=\"number\">1</span>], )))</span><br><span class=\"line\">    model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">    model.add(layers.Dense(<span class=\"number\">1</span>))   <span class=\"comment\">#没有激活，线性层</span></span><br><span class=\"line\">    model.compile(optimizer=<span class=\"string\">'rmsprop'</span>, loss=<span class=\"string\">'mse'</span>, metrics=[<span class=\"string\">'mae'</span>])</span><br><span class=\"line\">    <span class=\"keyword\">return</span> model</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#K折交叉验证</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">k = <span class=\"number\">4</span></span><br><span class=\"line\">num_val_samples = len(train_data) // k</span><br><span class=\"line\">num_epochs = <span class=\"number\">100</span>   <span class=\"comment\">#训练100轮次</span></span><br><span class=\"line\">all_scores = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(k):</span><br><span class=\"line\">    print(<span class=\"string\">'processing fold #'</span>, i)</span><br><span class=\"line\">    <span class=\"comment\">#准备验证数据：第k个分区的数据</span></span><br><span class=\"line\">    val_data = train_data[i * num_val_samples: (i + <span class=\"number\">1</span>) * num_val_samples]</span><br><span class=\"line\">    val_targets = train_targets[i * num_val_samples: (i + <span class=\"number\">1</span>) * num_val_samples]</span><br><span class=\"line\">    <span class=\"comment\">#准备训练数据：其他所有分区的数据</span></span><br><span class=\"line\">    partial_train_data = np.concatenate(</span><br><span class=\"line\">        [train_data[:i * num_val_samples],</span><br><span class=\"line\">         train_data[(i + <span class=\"number\">1</span>) * num_val_samples: ]],</span><br><span class=\"line\">        axis=<span class=\"number\">0</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    partial_train_targets = np.concatenate(</span><br><span class=\"line\">        [train_targets[:i * num_val_samples],</span><br><span class=\"line\">         train_targets[(i + <span class=\"number\">1</span>) * num_val_samples: ]],</span><br><span class=\"line\">        axis=<span class=\"number\">0</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\">#构建Keras模型（已编译）</span></span><br><span class=\"line\">    model = build_model()</span><br><span class=\"line\">    <span class=\"comment\">#训练模型（静默模式，verbose=0）</span></span><br><span class=\"line\">    model.fit(partial_train_data, partial_train_targets,</span><br><span class=\"line\">             epochs=num_epochs, batch_size=<span class=\"number\">1</span>, verbose=<span class=\"number\">0</span>)</span><br><span class=\"line\">    在验证数据上评估模型</span><br><span class=\"line\">    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=<span class=\"number\">0</span>)</span><br><span class=\"line\">    all_scores.append(val_mae)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">processing fold # 0</span><br><span class=\"line\">processing fold # 1</span><br><span class=\"line\">processing fold # 2</span><br><span class=\"line\">processing fold # 3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">all_scores</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[1.953495462342064, 2.7316349308089456, 2.4950007542525188, 2.304117675464932]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">np.mean(all_scores)</span><br><span class=\"line\"><span class=\"comment\">#差别很大</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2.371062205717115</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#重新训练 500轮次</span></span><br><span class=\"line\"><span class=\"comment\">#保存每折的验证结果</span></span><br><span class=\"line\">num_epochs = <span class=\"number\">500</span></span><br><span class=\"line\">all_mae_histories = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(k):</span><br><span class=\"line\">    print(<span class=\"string\">'processing fold #'</span>, i)</span><br><span class=\"line\">    val_data = train_data[i * num_val_samples: (i + <span class=\"number\">1</span>) * num_val_samples]</span><br><span class=\"line\">    val_targets = train_targets[i * num_val_samples: (i + <span class=\"number\">1</span>) * num_val_samples]</span><br><span class=\"line\">    </span><br><span class=\"line\">    partial_train_data = np.concatenate(</span><br><span class=\"line\">    [train_data[:i * num_val_samples],</span><br><span class=\"line\">     train_data[(i + <span class=\"number\">1</span>) * num_val_samples: ]],</span><br><span class=\"line\">    axis=<span class=\"number\">0</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    </span><br><span class=\"line\">    partial_train_targets = np.concatenate(</span><br><span class=\"line\">    [train_targets[:i * num_val_samples],</span><br><span class=\"line\">     train_targets[(i + <span class=\"number\">1</span>) * num_val_samples: ]],</span><br><span class=\"line\">    axis=<span class=\"number\">0</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    </span><br><span class=\"line\">    model = build_model()</span><br><span class=\"line\">    history = model.fit(partial_train_data, partial_train_targets,</span><br><span class=\"line\">                               validation_data=(val_data, val_targets),</span><br><span class=\"line\">                               epochs=num_epochs, batch_size=<span class=\"number\">1</span>, verbose=<span class=\"number\">0</span>)</span><br><span class=\"line\">    mae_history = history.history[<span class=\"string\">'val_mean_absolute_error'</span>]</span><br><span class=\"line\">    all_mae_histories.append(mae_history)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">processing fold # 0</span><br><span class=\"line\">processing fold # 1</span><br><span class=\"line\">processing fold # 2</span><br><span class=\"line\">processing fold # 3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#计算所有轮次中的K折验证分数平均值</span></span><br><span class=\"line\">average_mae_history = [</span><br><span class=\"line\">    np.mean([x[i] <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> all_mae_histories]) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(num_epochs)]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#绘制验证分数 纵轴范围较大，数据方差相对较大，难以看清规律，重新绘制</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(range(<span class=\"number\">1</span>, len(average_mae_history) + <span class=\"number\">1</span>), average_mae_history)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Validation MAE'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras4/output_11_0.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#重新绘制：删除前10个数据点，将每个数据点替换为前面数据点的指数移动平均值</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">smooth_curve</span><span class=\"params\">(points, factor=<span class=\"number\">0.9</span>)</span>:</span></span><br><span class=\"line\">    smoothed_points = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> point <span class=\"keyword\">in</span> points:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> smoothed_points:</span><br><span class=\"line\">            previous = smoothed_points[<span class=\"number\">-1</span>]</span><br><span class=\"line\">            smoothed_points.append(previous * factor + point * (<span class=\"number\">1</span> - factor))</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            smoothed_points.append(point)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> smoothed_points</span><br><span class=\"line\"></span><br><span class=\"line\">smooth_mae_history = smooth_curve(average_mae_history[<span class=\"number\">10</span>: ])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(range(<span class=\"number\">1</span>, len(smooth_mae_history) + <span class=\"number\">1</span>), smooth_mae_history)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Validation MAE'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras4/output_12_0.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#上一轮出现过拟合</span></span><br><span class=\"line\"><span class=\"comment\">#训练最终模型</span></span><br><span class=\"line\">model = build_model()</span><br><span class=\"line\">model.fit(train_data, train_targets, epochs=<span class=\"number\">80</span>, batch_size=<span class=\"number\">16</span>, verbose=<span class=\"number\">0</span>)</span><br><span class=\"line\">test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">102/102 [==============================] - 0s 2ms/step</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#最终结果</span></span><br><span class=\"line\">test_mae_score</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2.577465954948874</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test_mse_score</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">16.48435390696806</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#加载波士顿房价数据</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.datasets <span class=\"keyword\">import</span> boston_housing</span><br><span class=\"line\">(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Using TensorFlow backend.</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz</span><br><span class=\"line\">57344/57026 [==============================] - 1s 10us/step</span><br></pre></td></tr></table></figure>","more":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data.shape</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(404, 13)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test_data.shape</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(102, 13)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_targets</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,</span><br><span class=\"line\">       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,</span><br><span class=\"line\">       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,</span><br><span class=\"line\">       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,</span><br><span class=\"line\">       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,</span><br><span class=\"line\">       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,</span><br><span class=\"line\">       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,</span><br><span class=\"line\">       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,</span><br><span class=\"line\">       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,</span><br><span class=\"line\">       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,</span><br><span class=\"line\">       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,</span><br><span class=\"line\">       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,</span><br><span class=\"line\">       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,</span><br><span class=\"line\">       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,</span><br><span class=\"line\">       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,</span><br><span class=\"line\">       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,</span><br><span class=\"line\">        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,</span><br><span class=\"line\">       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,</span><br><span class=\"line\">       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,</span><br><span class=\"line\">       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,</span><br><span class=\"line\">       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,</span><br><span class=\"line\">       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,</span><br><span class=\"line\">       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,</span><br><span class=\"line\">       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,</span><br><span class=\"line\">       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,</span><br><span class=\"line\">       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,</span><br><span class=\"line\">        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,</span><br><span class=\"line\">        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,</span><br><span class=\"line\">       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,</span><br><span class=\"line\">       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,</span><br><span class=\"line\">       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,</span><br><span class=\"line\">       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,</span><br><span class=\"line\">       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,</span><br><span class=\"line\">       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,</span><br><span class=\"line\">       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,</span><br><span class=\"line\">       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,</span><br><span class=\"line\">       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#数据特征标准化  （特征-平均值）/标准差</span></span><br><span class=\"line\">mean = train_data.mean(axis=<span class=\"number\">0</span>)   <span class=\"comment\">#特征平均值</span></span><br><span class=\"line\">train_data -= mean</span><br><span class=\"line\">std = train_data.std(axis=<span class=\"number\">0</span>)   <span class=\"comment\">#标准差</span></span><br><span class=\"line\">train_data /= std</span><br><span class=\"line\"></span><br><span class=\"line\">test_data -= mean</span><br><span class=\"line\">test_data /= std</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#构建网络 模型定义</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> models</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> layers</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#需要将同一个模型多次实例化，所以用一个函数来构建模型</span></span><br><span class=\"line\"><span class=\"comment\">#MSE损失函数（mean squared error）：均方误差，预测值与目标值之差的平方</span></span><br><span class=\"line\"><span class=\"comment\">#MAE指标（mean absolute error）：平均绝对误差，预测值与目标值之差的绝对值</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">build_model</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    model = models.Sequential()</span><br><span class=\"line\">    model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>, input_shape=(train_data.shape[<span class=\"number\">1</span>], )))</span><br><span class=\"line\">    model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">    model.add(layers.Dense(<span class=\"number\">1</span>))   <span class=\"comment\">#没有激活，线性层</span></span><br><span class=\"line\">    model.compile(optimizer=<span class=\"string\">'rmsprop'</span>, loss=<span class=\"string\">'mse'</span>, metrics=[<span class=\"string\">'mae'</span>])</span><br><span class=\"line\">    <span class=\"keyword\">return</span> model</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#K折交叉验证</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">k = <span class=\"number\">4</span></span><br><span class=\"line\">num_val_samples = len(train_data) // k</span><br><span class=\"line\">num_epochs = <span class=\"number\">100</span>   <span class=\"comment\">#训练100轮次</span></span><br><span class=\"line\">all_scores = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(k):</span><br><span class=\"line\">    print(<span class=\"string\">'processing fold #'</span>, i)</span><br><span class=\"line\">    <span class=\"comment\">#准备验证数据：第k个分区的数据</span></span><br><span class=\"line\">    val_data = train_data[i * num_val_samples: (i + <span class=\"number\">1</span>) * num_val_samples]</span><br><span class=\"line\">    val_targets = train_targets[i * num_val_samples: (i + <span class=\"number\">1</span>) * num_val_samples]</span><br><span class=\"line\">    <span class=\"comment\">#准备训练数据：其他所有分区的数据</span></span><br><span class=\"line\">    partial_train_data = np.concatenate(</span><br><span class=\"line\">        [train_data[:i * num_val_samples],</span><br><span class=\"line\">         train_data[(i + <span class=\"number\">1</span>) * num_val_samples: ]],</span><br><span class=\"line\">        axis=<span class=\"number\">0</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    partial_train_targets = np.concatenate(</span><br><span class=\"line\">        [train_targets[:i * num_val_samples],</span><br><span class=\"line\">         train_targets[(i + <span class=\"number\">1</span>) * num_val_samples: ]],</span><br><span class=\"line\">        axis=<span class=\"number\">0</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    <span class=\"comment\">#构建Keras模型（已编译）</span></span><br><span class=\"line\">    model = build_model()</span><br><span class=\"line\">    <span class=\"comment\">#训练模型（静默模式，verbose=0）</span></span><br><span class=\"line\">    model.fit(partial_train_data, partial_train_targets,</span><br><span class=\"line\">             epochs=num_epochs, batch_size=<span class=\"number\">1</span>, verbose=<span class=\"number\">0</span>)</span><br><span class=\"line\">    在验证数据上评估模型</span><br><span class=\"line\">    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=<span class=\"number\">0</span>)</span><br><span class=\"line\">    all_scores.append(val_mae)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">processing fold # 0</span><br><span class=\"line\">processing fold # 1</span><br><span class=\"line\">processing fold # 2</span><br><span class=\"line\">processing fold # 3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">all_scores</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[1.953495462342064, 2.7316349308089456, 2.4950007542525188, 2.304117675464932]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">np.mean(all_scores)</span><br><span class=\"line\"><span class=\"comment\">#差别很大</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2.371062205717115</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#重新训练 500轮次</span></span><br><span class=\"line\"><span class=\"comment\">#保存每折的验证结果</span></span><br><span class=\"line\">num_epochs = <span class=\"number\">500</span></span><br><span class=\"line\">all_mae_histories = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(k):</span><br><span class=\"line\">    print(<span class=\"string\">'processing fold #'</span>, i)</span><br><span class=\"line\">    val_data = train_data[i * num_val_samples: (i + <span class=\"number\">1</span>) * num_val_samples]</span><br><span class=\"line\">    val_targets = train_targets[i * num_val_samples: (i + <span class=\"number\">1</span>) * num_val_samples]</span><br><span class=\"line\">    </span><br><span class=\"line\">    partial_train_data = np.concatenate(</span><br><span class=\"line\">    [train_data[:i * num_val_samples],</span><br><span class=\"line\">     train_data[(i + <span class=\"number\">1</span>) * num_val_samples: ]],</span><br><span class=\"line\">    axis=<span class=\"number\">0</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    </span><br><span class=\"line\">    partial_train_targets = np.concatenate(</span><br><span class=\"line\">    [train_targets[:i * num_val_samples],</span><br><span class=\"line\">     train_targets[(i + <span class=\"number\">1</span>) * num_val_samples: ]],</span><br><span class=\"line\">    axis=<span class=\"number\">0</span></span><br><span class=\"line\">    )</span><br><span class=\"line\">    </span><br><span class=\"line\">    model = build_model()</span><br><span class=\"line\">    history = model.fit(partial_train_data, partial_train_targets,</span><br><span class=\"line\">                               validation_data=(val_data, val_targets),</span><br><span class=\"line\">                               epochs=num_epochs, batch_size=<span class=\"number\">1</span>, verbose=<span class=\"number\">0</span>)</span><br><span class=\"line\">    mae_history = history.history[<span class=\"string\">'val_mean_absolute_error'</span>]</span><br><span class=\"line\">    all_mae_histories.append(mae_history)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">processing fold # 0</span><br><span class=\"line\">processing fold # 1</span><br><span class=\"line\">processing fold # 2</span><br><span class=\"line\">processing fold # 3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#计算所有轮次中的K折验证分数平均值</span></span><br><span class=\"line\">average_mae_history = [</span><br><span class=\"line\">    np.mean([x[i] <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> all_mae_histories]) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(num_epochs)]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#绘制验证分数 纵轴范围较大，数据方差相对较大，难以看清规律，重新绘制</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(range(<span class=\"number\">1</span>, len(average_mae_history) + <span class=\"number\">1</span>), average_mae_history)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Validation MAE'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras4/output_11_0.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#重新绘制：删除前10个数据点，将每个数据点替换为前面数据点的指数移动平均值</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">smooth_curve</span><span class=\"params\">(points, factor=<span class=\"number\">0.9</span>)</span>:</span></span><br><span class=\"line\">    smoothed_points = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> point <span class=\"keyword\">in</span> points:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> smoothed_points:</span><br><span class=\"line\">            previous = smoothed_points[<span class=\"number\">-1</span>]</span><br><span class=\"line\">            smoothed_points.append(previous * factor + point * (<span class=\"number\">1</span> - factor))</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            smoothed_points.append(point)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> smoothed_points</span><br><span class=\"line\"></span><br><span class=\"line\">smooth_mae_history = smooth_curve(average_mae_history[<span class=\"number\">10</span>: ])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(range(<span class=\"number\">1</span>, len(smooth_mae_history) + <span class=\"number\">1</span>), smooth_mae_history)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Validation MAE'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras4/output_12_0.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#上一轮出现过拟合</span></span><br><span class=\"line\"><span class=\"comment\">#训练最终模型</span></span><br><span class=\"line\">model = build_model()</span><br><span class=\"line\">model.fit(train_data, train_targets, epochs=<span class=\"number\">80</span>, batch_size=<span class=\"number\">16</span>, verbose=<span class=\"number\">0</span>)</span><br><span class=\"line\">test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">102/102 [==============================] - 0s 2ms/step</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#最终结果</span></span><br><span class=\"line\">test_mae_score</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2.577465954948874</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test_mse_score</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">16.48435390696806</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>"},{"title":"Markdown：空格","date":"2019-04-05T07:19:24.000Z","_content":"\n半角空格 &amp;ensp;\n\n全角空格 &amp;emsp;","source":"_posts/Markdown空格.md","raw":"---\ntitle: Markdown：空格\ndate: 2019-04-05 15:19:24\ntags:\n---\n\n半角空格 &amp;ensp;\n\n全角空格 &amp;emsp;","slug":"Markdown空格","published":1,"updated":"2019-04-05T07:29:38.981Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju3r7xhj0008apndge2qmxl4","content":"<p>半角空格 &amp;ensp;</p>\n<p>全角空格 &amp;emsp;</p>\n","site":{"data":{}},"excerpt":"","more":"<p>半角空格 &amp;ensp;</p>\n<p>全角空格 &amp;emsp;</p>\n"},{"title":"KERAS学习（三）：新闻分类-多分类问题","date":"2019-01-28T12:08:44.000Z","photos":["output_12_0.png"],"_content":"\n```python\n#单标签 多分类\n#加载路透社数据集\nfrom keras.datasets import reuters\n(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n```\n\n```\nUsing TensorFlow backend.\n```\n\n```\nDownloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n2113536/2110848 [==============================] - 7s 3us/step\n```\n\n<!-- more -->\n\n```python\nlen(train_data)\n```\n\n\n\n```\n8982\n```\n\n\n\n```python\nlen(test_data)\n```\n\n\n\n```\n2246\n```\n\n\n\n```python\ntrain_data[10]\n```\n\n\n\n```\n[1,\n 245,\n 273,\n 207,\n 156,\n 53,\n 74,\n 160,\n 26,\n 14,\n 46,\n 296,\n 26,\n 39,\n 74,\n 2979,\n 3554,\n 14,\n 46,\n 4689,\n 4329,\n 86,\n 61,\n 3499,\n 4795,\n 14,\n 61,\n 451,\n 4329,\n 17,\n 12]\n\n```\n\n\n\n```python\n#将索引解码为新闻文本\nword_index = reuters.get_word_index()\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\ndecoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n#第一个新闻\n\n```\n\n```\nDownloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n557056/550378 [==============================] - 7s 13us/step\n\n```\n\n\n\n```python\ntrain_labels[0]\n\n```\n\n\n\n```\n3\n\n```\n\n\n\n```python\n#数据向量化\nimport numpy as np\ndef vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1\n    return results\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)\n\n```\n\n```python\n#标签向量化\ndef to_one_hot(labels, dimension=46):\n    results = np.zeros((len(labels), dimension))\n    for i, label in enumerate(labels):\n        results[i, label] = 1\n    return results\n\none_hot_train_labels = to_one_hot(train_labels)\none_hot_test_labels = to_one_hot(test_labels)\n\n```\n\n```python\n#构建网络 模型定义\n#激活函数 输出在46个不同输出类别上的概率分布\nfrom keras import models\nfrom keras import layers\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(46, activation='softmax'))\n\n```\n\n```python\n#编译模型\n#分类交叉熵 衡量两个概率分布之间的距离\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n\n```\n\n```python\n#留出验证集\nx_val = x_train[:1000]\npartial_x_train = x_train[1000:]\n\ny_val = one_hot_train_labels[:1000]\npartial_y_train = one_hot_train_labels[1000:]\n\n```\n\n```python\n#训练模型\nhistory = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))\n\n```\n\n```\nTrain on 7982 samples, validate on 1000 samples\nEpoch 1/20\n7982/7982 [==============================] - 4s 452us/step - loss: 2.4979 - acc: 0.4915 - val_loss: 1.6824 - val_acc: 0.6470\nEpoch 2/20\n7982/7982 [==============================] - 2s 264us/step - loss: 1.3942 - acc: 0.7045 - val_loss: 1.2821 - val_acc: 0.7160\nEpoch 3/20\n7982/7982 [==============================] - 2s 212us/step - loss: 1.0509 - acc: 0.7686 - val_loss: 1.1187 - val_acc: 0.7640\nEpoch 4/20\n7982/7982 [==============================] - 1s 175us/step - loss: 0.8256 - acc: 0.8281 - val_loss: 1.0233 - val_acc: 0.7740\nEpoch 5/20\n7982/7982 [==============================] - 1s 175us/step - loss: 0.6607 - acc: 0.8639 - val_loss: 0.9730 - val_acc: 0.7940\nEpoch 6/20\n7982/7982 [==============================] - 1s 188us/step - loss: 0.5260 - acc: 0.8928 - val_loss: 0.9196 - val_acc: 0.8100\nEpoch 7/20\n7982/7982 [==============================] - 1s 183us/step - loss: 0.4292 - acc: 0.9116 - val_loss: 0.9124 - val_acc: 0.8030\nEpoch 8/20\n7982/7982 [==============================] - 2s 201us/step - loss: 0.3498 - acc: 0.9270 - val_loss: 0.8942 - val_acc: 0.8170\nEpoch 9/20\n7982/7982 [==============================] - 2s 194us/step - loss: 0.2894 - acc: 0.9385 - val_loss: 0.9147 - val_acc: 0.8060\nEpoch 10/20\n7982/7982 [==============================] - 1s 181us/step - loss: 0.2451 - acc: 0.9453 - val_loss: 0.9124 - val_acc: 0.8130\nEpoch 11/20\n7982/7982 [==============================] - 1s 175us/step - loss: 0.2102 - acc: 0.9484 - val_loss: 0.9480 - val_acc: 0.8120\nEpoch 12/20\n7982/7982 [==============================] - 1s 173us/step - loss: 0.1881 - acc: 0.9523 - val_loss: 0.9600 - val_acc: 0.8050\nEpoch 13/20\n7982/7982 [==============================] - 2s 189us/step - loss: 0.1662 - acc: 0.9526 - val_loss: 0.9964 - val_acc: 0.7960\nEpoch 14/20\n7982/7982 [==============================] - 2s 229us/step - loss: 0.1530 - acc: 0.9550 - val_loss: 0.9766 - val_acc: 0.8050\nEpoch 15/20\n7982/7982 [==============================] - 2s 194us/step - loss: 0.1457 - acc: 0.9548 - val_loss: 1.0243 - val_acc: 0.7970\nEpoch 16/20\n7982/7982 [==============================] - 1s 176us/step - loss: 0.1332 - acc: 0.9553 - val_loss: 1.0392 - val_acc: 0.8020\nEpoch 17/20\n7982/7982 [==============================] - 1s 171us/step - loss: 0.1260 - acc: 0.9553 - val_loss: 1.0396 - val_acc: 0.7980\nEpoch 18/20\n7982/7982 [==============================] - 1s 183us/step - loss: 0.1169 - acc: 0.9560 - val_loss: 1.0390 - val_acc: 0.8150\nEpoch 19/20\n7982/7982 [==============================] - 1s 182us/step - loss: 0.1165 - acc: 0.9569 - val_loss: 1.0301 - val_acc: 0.8090\nEpoch 20/20\n7982/7982 [==============================] - 1s 177us/step - loss: 0.1140 - acc: 0.9580 - val_loss: 1.0484 - val_acc: 0.8030\n\n```\n\n\n\n```python\n#绘制训练损失和验证损失\nimport matplotlib.pyplot as plt\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n```\n\n![png](Keras3/output_12_0.png)\n\n\n\n```python\nplt.clf()\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n```\n\n![png](Keras3/output_13_0.png)\n\n\n\n```python\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(46, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val, y_val))\nresults = model.evaluate(x_test, one_hot_test_labels)\n\n```\n\n```\nTrain on 7982 samples, validate on 1000 samples\nEpoch 1/9\n7982/7982 [==============================] - 4s 494us/step - loss: 2.5416 - acc: 0.5223 - val_loss: 1.6816 - val_acc: 0.6490\nEpoch 2/9\n7982/7982 [==============================] - 2s 271us/step - loss: 1.3779 - acc: 0.7096 - val_loss: 1.2817 - val_acc: 0.7240\nEpoch 3/9\n7982/7982 [==============================] - 2s 225us/step - loss: 1.0201 - acc: 0.7783 - val_loss: 1.1325 - val_acc: 0.7500\nEpoch 4/9\n7982/7982 [==============================] - 1s 182us/step - loss: 0.8026 - acc: 0.8237 - val_loss: 1.0541 - val_acc: 0.7580\nEpoch 5/9\n7982/7982 [==============================] - 1s 180us/step - loss: 0.6429 - acc: 0.8617 - val_loss: 0.9743 - val_acc: 0.8000\nEpoch 6/9\n7982/7982 [==============================] - 2s 191us/step - loss: 0.5152 - acc: 0.8933 - val_loss: 0.9122 - val_acc: 0.8130\nEpoch 7/9\n7982/7982 [==============================] - 1s 174us/step - loss: 0.4152 - acc: 0.9138 - val_loss: 0.8975 - val_acc: 0.8240\nEpoch 8/9\n7982/7982 [==============================] - 1s 170us/step - loss: 0.3377 - acc: 0.9276 - val_loss: 0.8781 - val_acc: 0.8240\nEpoch 9/9\n7982/7982 [==============================] - 2s 193us/step - loss: 0.2803 - acc: 0.9369 - val_loss: 0.9426 - val_acc: 0.8020\n2246/2246 [==============================] - 1s 354us/step\n\n```\n\n\n\n```python\nresults\n\n```\n\n\n\n```\n[1.0234324284567964, 0.7782724844698171]\n\n```\n\n\n\n```python\n#在新数据上生成预测结果\npredictions = model.predict(x_test)\n\n```\n\n```python\npredictions[0].shape\n\n```\n\n\n\n```\n(46,)\n\n```\n\n\n\n```python\nnp.sum(predictions[0])\n\n```\n\n\n\n```\n0.99999994\n\n```\n\n\n\n```python\nnp.argmax(predictions[0])\n\n```\n\n\n\n```\n3\n```\n\n\n\n```python\npredictions[0]\n```\n\n\n\n```\narray([9.00706073e-06, 1.12914335e-04, 3.39240214e-05, 9.69965935e-01,\n       1.83314960e-02, 1.24670180e-07, 7.63048884e-05, 3.95889074e-05,\n       3.83749488e-03, 2.36399887e-06, 3.72867580e-05, 9.80967656e-04,\n       5.15155261e-05, 2.07923913e-05, 5.04263471e-06, 1.48046838e-05,\n       1.14349602e-03, 1.92527470e-04, 3.11047770e-04, 1.02656987e-03,\n       1.14359299e-03, 5.38451481e-04, 4.49636536e-06, 7.14166526e-05,\n       9.90290209e-06, 2.55455700e-04, 2.65549829e-06, 2.30972691e-05,\n       5.41368354e-06, 1.46480859e-04, 2.82360037e-04, 1.54729976e-04,\n       1.18201979e-05, 5.56262385e-05, 4.05374340e-05, 1.80534789e-05,\n       1.31222856e-04, 5.19382884e-05, 1.25783903e-04, 2.72022764e-04,\n       3.01298915e-05, 3.90922709e-04, 1.79568303e-06, 2.20499132e-05,\n       6.57706141e-06, 1.01889082e-05], dtype=float32)\n```\n\n\n\n```python\npredictions[0][3]\n```\n\n\n\n```\n0.96996593\n```\n\n\n\n```python\n\n```","source":"_posts/Keras3.md","raw":"---\ntitle: KERAS学习（三）：新闻分类-多分类问题\ndate: 2019-01-28 20:08:44\ntags:\n    - Keras\ncategories:\n    - Notes\nphotos:\n    - output_12_0.png\n---\n\n```python\n#单标签 多分类\n#加载路透社数据集\nfrom keras.datasets import reuters\n(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n```\n\n```\nUsing TensorFlow backend.\n```\n\n```\nDownloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n2113536/2110848 [==============================] - 7s 3us/step\n```\n\n<!-- more -->\n\n```python\nlen(train_data)\n```\n\n\n\n```\n8982\n```\n\n\n\n```python\nlen(test_data)\n```\n\n\n\n```\n2246\n```\n\n\n\n```python\ntrain_data[10]\n```\n\n\n\n```\n[1,\n 245,\n 273,\n 207,\n 156,\n 53,\n 74,\n 160,\n 26,\n 14,\n 46,\n 296,\n 26,\n 39,\n 74,\n 2979,\n 3554,\n 14,\n 46,\n 4689,\n 4329,\n 86,\n 61,\n 3499,\n 4795,\n 14,\n 61,\n 451,\n 4329,\n 17,\n 12]\n\n```\n\n\n\n```python\n#将索引解码为新闻文本\nword_index = reuters.get_word_index()\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\ndecoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n#第一个新闻\n\n```\n\n```\nDownloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n557056/550378 [==============================] - 7s 13us/step\n\n```\n\n\n\n```python\ntrain_labels[0]\n\n```\n\n\n\n```\n3\n\n```\n\n\n\n```python\n#数据向量化\nimport numpy as np\ndef vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1\n    return results\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)\n\n```\n\n```python\n#标签向量化\ndef to_one_hot(labels, dimension=46):\n    results = np.zeros((len(labels), dimension))\n    for i, label in enumerate(labels):\n        results[i, label] = 1\n    return results\n\none_hot_train_labels = to_one_hot(train_labels)\none_hot_test_labels = to_one_hot(test_labels)\n\n```\n\n```python\n#构建网络 模型定义\n#激活函数 输出在46个不同输出类别上的概率分布\nfrom keras import models\nfrom keras import layers\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(46, activation='softmax'))\n\n```\n\n```python\n#编译模型\n#分类交叉熵 衡量两个概率分布之间的距离\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n\n```\n\n```python\n#留出验证集\nx_val = x_train[:1000]\npartial_x_train = x_train[1000:]\n\ny_val = one_hot_train_labels[:1000]\npartial_y_train = one_hot_train_labels[1000:]\n\n```\n\n```python\n#训练模型\nhistory = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))\n\n```\n\n```\nTrain on 7982 samples, validate on 1000 samples\nEpoch 1/20\n7982/7982 [==============================] - 4s 452us/step - loss: 2.4979 - acc: 0.4915 - val_loss: 1.6824 - val_acc: 0.6470\nEpoch 2/20\n7982/7982 [==============================] - 2s 264us/step - loss: 1.3942 - acc: 0.7045 - val_loss: 1.2821 - val_acc: 0.7160\nEpoch 3/20\n7982/7982 [==============================] - 2s 212us/step - loss: 1.0509 - acc: 0.7686 - val_loss: 1.1187 - val_acc: 0.7640\nEpoch 4/20\n7982/7982 [==============================] - 1s 175us/step - loss: 0.8256 - acc: 0.8281 - val_loss: 1.0233 - val_acc: 0.7740\nEpoch 5/20\n7982/7982 [==============================] - 1s 175us/step - loss: 0.6607 - acc: 0.8639 - val_loss: 0.9730 - val_acc: 0.7940\nEpoch 6/20\n7982/7982 [==============================] - 1s 188us/step - loss: 0.5260 - acc: 0.8928 - val_loss: 0.9196 - val_acc: 0.8100\nEpoch 7/20\n7982/7982 [==============================] - 1s 183us/step - loss: 0.4292 - acc: 0.9116 - val_loss: 0.9124 - val_acc: 0.8030\nEpoch 8/20\n7982/7982 [==============================] - 2s 201us/step - loss: 0.3498 - acc: 0.9270 - val_loss: 0.8942 - val_acc: 0.8170\nEpoch 9/20\n7982/7982 [==============================] - 2s 194us/step - loss: 0.2894 - acc: 0.9385 - val_loss: 0.9147 - val_acc: 0.8060\nEpoch 10/20\n7982/7982 [==============================] - 1s 181us/step - loss: 0.2451 - acc: 0.9453 - val_loss: 0.9124 - val_acc: 0.8130\nEpoch 11/20\n7982/7982 [==============================] - 1s 175us/step - loss: 0.2102 - acc: 0.9484 - val_loss: 0.9480 - val_acc: 0.8120\nEpoch 12/20\n7982/7982 [==============================] - 1s 173us/step - loss: 0.1881 - acc: 0.9523 - val_loss: 0.9600 - val_acc: 0.8050\nEpoch 13/20\n7982/7982 [==============================] - 2s 189us/step - loss: 0.1662 - acc: 0.9526 - val_loss: 0.9964 - val_acc: 0.7960\nEpoch 14/20\n7982/7982 [==============================] - 2s 229us/step - loss: 0.1530 - acc: 0.9550 - val_loss: 0.9766 - val_acc: 0.8050\nEpoch 15/20\n7982/7982 [==============================] - 2s 194us/step - loss: 0.1457 - acc: 0.9548 - val_loss: 1.0243 - val_acc: 0.7970\nEpoch 16/20\n7982/7982 [==============================] - 1s 176us/step - loss: 0.1332 - acc: 0.9553 - val_loss: 1.0392 - val_acc: 0.8020\nEpoch 17/20\n7982/7982 [==============================] - 1s 171us/step - loss: 0.1260 - acc: 0.9553 - val_loss: 1.0396 - val_acc: 0.7980\nEpoch 18/20\n7982/7982 [==============================] - 1s 183us/step - loss: 0.1169 - acc: 0.9560 - val_loss: 1.0390 - val_acc: 0.8150\nEpoch 19/20\n7982/7982 [==============================] - 1s 182us/step - loss: 0.1165 - acc: 0.9569 - val_loss: 1.0301 - val_acc: 0.8090\nEpoch 20/20\n7982/7982 [==============================] - 1s 177us/step - loss: 0.1140 - acc: 0.9580 - val_loss: 1.0484 - val_acc: 0.8030\n\n```\n\n\n\n```python\n#绘制训练损失和验证损失\nimport matplotlib.pyplot as plt\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n```\n\n![png](Keras3/output_12_0.png)\n\n\n\n```python\nplt.clf()\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n\n```\n\n![png](Keras3/output_13_0.png)\n\n\n\n```python\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(46, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val, y_val))\nresults = model.evaluate(x_test, one_hot_test_labels)\n\n```\n\n```\nTrain on 7982 samples, validate on 1000 samples\nEpoch 1/9\n7982/7982 [==============================] - 4s 494us/step - loss: 2.5416 - acc: 0.5223 - val_loss: 1.6816 - val_acc: 0.6490\nEpoch 2/9\n7982/7982 [==============================] - 2s 271us/step - loss: 1.3779 - acc: 0.7096 - val_loss: 1.2817 - val_acc: 0.7240\nEpoch 3/9\n7982/7982 [==============================] - 2s 225us/step - loss: 1.0201 - acc: 0.7783 - val_loss: 1.1325 - val_acc: 0.7500\nEpoch 4/9\n7982/7982 [==============================] - 1s 182us/step - loss: 0.8026 - acc: 0.8237 - val_loss: 1.0541 - val_acc: 0.7580\nEpoch 5/9\n7982/7982 [==============================] - 1s 180us/step - loss: 0.6429 - acc: 0.8617 - val_loss: 0.9743 - val_acc: 0.8000\nEpoch 6/9\n7982/7982 [==============================] - 2s 191us/step - loss: 0.5152 - acc: 0.8933 - val_loss: 0.9122 - val_acc: 0.8130\nEpoch 7/9\n7982/7982 [==============================] - 1s 174us/step - loss: 0.4152 - acc: 0.9138 - val_loss: 0.8975 - val_acc: 0.8240\nEpoch 8/9\n7982/7982 [==============================] - 1s 170us/step - loss: 0.3377 - acc: 0.9276 - val_loss: 0.8781 - val_acc: 0.8240\nEpoch 9/9\n7982/7982 [==============================] - 2s 193us/step - loss: 0.2803 - acc: 0.9369 - val_loss: 0.9426 - val_acc: 0.8020\n2246/2246 [==============================] - 1s 354us/step\n\n```\n\n\n\n```python\nresults\n\n```\n\n\n\n```\n[1.0234324284567964, 0.7782724844698171]\n\n```\n\n\n\n```python\n#在新数据上生成预测结果\npredictions = model.predict(x_test)\n\n```\n\n```python\npredictions[0].shape\n\n```\n\n\n\n```\n(46,)\n\n```\n\n\n\n```python\nnp.sum(predictions[0])\n\n```\n\n\n\n```\n0.99999994\n\n```\n\n\n\n```python\nnp.argmax(predictions[0])\n\n```\n\n\n\n```\n3\n```\n\n\n\n```python\npredictions[0]\n```\n\n\n\n```\narray([9.00706073e-06, 1.12914335e-04, 3.39240214e-05, 9.69965935e-01,\n       1.83314960e-02, 1.24670180e-07, 7.63048884e-05, 3.95889074e-05,\n       3.83749488e-03, 2.36399887e-06, 3.72867580e-05, 9.80967656e-04,\n       5.15155261e-05, 2.07923913e-05, 5.04263471e-06, 1.48046838e-05,\n       1.14349602e-03, 1.92527470e-04, 3.11047770e-04, 1.02656987e-03,\n       1.14359299e-03, 5.38451481e-04, 4.49636536e-06, 7.14166526e-05,\n       9.90290209e-06, 2.55455700e-04, 2.65549829e-06, 2.30972691e-05,\n       5.41368354e-06, 1.46480859e-04, 2.82360037e-04, 1.54729976e-04,\n       1.18201979e-05, 5.56262385e-05, 4.05374340e-05, 1.80534789e-05,\n       1.31222856e-04, 5.19382884e-05, 1.25783903e-04, 2.72022764e-04,\n       3.01298915e-05, 3.90922709e-04, 1.79568303e-06, 2.20499132e-05,\n       6.57706141e-06, 1.01889082e-05], dtype=float32)\n```\n\n\n\n```python\npredictions[0][3]\n```\n\n\n\n```\n0.96996593\n```\n\n\n\n```python\n\n```","slug":"Keras3","published":1,"updated":"2019-01-28T12:16:57.788Z","comments":1,"layout":"post","link":"","_id":"cju3r7xhl0009apndx9qo4zs1","content":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#单标签 多分类</span></span><br><span class=\"line\"><span class=\"comment\">#加载路透社数据集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.datasets <span class=\"keyword\">import</span> reuters</span><br><span class=\"line\">(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=<span class=\"number\">10000</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Using TensorFlow backend.</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz</span><br><span class=\"line\">2113536/2110848 [==============================] - 7s 3us/step</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">len(train_data)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">8982</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">len(test_data)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2246</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data[<span class=\"number\">10</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[1,</span><br><span class=\"line\"> 245,</span><br><span class=\"line\"> 273,</span><br><span class=\"line\"> 207,</span><br><span class=\"line\"> 156,</span><br><span class=\"line\"> 53,</span><br><span class=\"line\"> 74,</span><br><span class=\"line\"> 160,</span><br><span class=\"line\"> 26,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 46,</span><br><span class=\"line\"> 296,</span><br><span class=\"line\"> 26,</span><br><span class=\"line\"> 39,</span><br><span class=\"line\"> 74,</span><br><span class=\"line\"> 2979,</span><br><span class=\"line\"> 3554,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 46,</span><br><span class=\"line\"> 4689,</span><br><span class=\"line\"> 4329,</span><br><span class=\"line\"> 86,</span><br><span class=\"line\"> 61,</span><br><span class=\"line\"> 3499,</span><br><span class=\"line\"> 4795,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 61,</span><br><span class=\"line\"> 451,</span><br><span class=\"line\"> 4329,</span><br><span class=\"line\"> 17,</span><br><span class=\"line\"> 12]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#将索引解码为新闻文本</span></span><br><span class=\"line\">word_index = reuters.get_word_index()</span><br><span class=\"line\">reverse_word_index = dict([(value, key) <span class=\"keyword\">for</span> (key, value) <span class=\"keyword\">in</span> word_index.items()])</span><br><span class=\"line\">decoded_newswire = <span class=\"string\">' '</span>.join([reverse_word_index.get(i - <span class=\"number\">3</span>, <span class=\"string\">'?'</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> train_data[<span class=\"number\">0</span>]])</span><br><span class=\"line\"><span class=\"comment\">#第一个新闻</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json</span><br><span class=\"line\">557056/550378 [==============================] - 7s 13us/step</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_labels[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#数据向量化</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">vectorize_sequences</span><span class=\"params\">(sequences, dimension=<span class=\"number\">10000</span>)</span>:</span></span><br><span class=\"line\">    results = np.zeros((len(sequences), dimension))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, sequence <span class=\"keyword\">in</span> enumerate(sequences):</span><br><span class=\"line\">        results[i, sequence] = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> results</span><br><span class=\"line\">x_train = vectorize_sequences(train_data)</span><br><span class=\"line\">x_test = vectorize_sequences(test_data)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#标签向量化</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">to_one_hot</span><span class=\"params\">(labels, dimension=<span class=\"number\">46</span>)</span>:</span></span><br><span class=\"line\">    results = np.zeros((len(labels), dimension))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, label <span class=\"keyword\">in</span> enumerate(labels):</span><br><span class=\"line\">        results[i, label] = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> results</span><br><span class=\"line\"></span><br><span class=\"line\">one_hot_train_labels = to_one_hot(train_labels)</span><br><span class=\"line\">one_hot_test_labels = to_one_hot(test_labels)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#构建网络 模型定义</span></span><br><span class=\"line\"><span class=\"comment\">#激活函数 输出在46个不同输出类别上的概率分布</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> models</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> layers</span><br><span class=\"line\"></span><br><span class=\"line\">model = models.Sequential()</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>, input_shape=(<span class=\"number\">10000</span>,)))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">46</span>, activation=<span class=\"string\">'softmax'</span>))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#编译模型</span></span><br><span class=\"line\"><span class=\"comment\">#分类交叉熵 衡量两个概率分布之间的距离</span></span><br><span class=\"line\">model.compile(optimizer=<span class=\"string\">'rmsprop'</span>, loss=<span class=\"string\">'categorical_crossentropy'</span>, metrics=[<span class=\"string\">'accuracy'</span>])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#留出验证集</span></span><br><span class=\"line\">x_val = x_train[:<span class=\"number\">1000</span>]</span><br><span class=\"line\">partial_x_train = x_train[<span class=\"number\">1000</span>:]</span><br><span class=\"line\"></span><br><span class=\"line\">y_val = one_hot_train_labels[:<span class=\"number\">1000</span>]</span><br><span class=\"line\">partial_y_train = one_hot_train_labels[<span class=\"number\">1000</span>:]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#训练模型</span></span><br><span class=\"line\">history = model.fit(partial_x_train, partial_y_train, epochs=<span class=\"number\">20</span>, batch_size=<span class=\"number\">512</span>, validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Train on 7982 samples, validate on 1000 samples</span><br><span class=\"line\">Epoch 1/20</span><br><span class=\"line\">7982/7982 [==============================] - 4s 452us/step - loss: 2.4979 - acc: 0.4915 - val_loss: 1.6824 - val_acc: 0.6470</span><br><span class=\"line\">Epoch 2/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 264us/step - loss: 1.3942 - acc: 0.7045 - val_loss: 1.2821 - val_acc: 0.7160</span><br><span class=\"line\">Epoch 3/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 212us/step - loss: 1.0509 - acc: 0.7686 - val_loss: 1.1187 - val_acc: 0.7640</span><br><span class=\"line\">Epoch 4/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 175us/step - loss: 0.8256 - acc: 0.8281 - val_loss: 1.0233 - val_acc: 0.7740</span><br><span class=\"line\">Epoch 5/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 175us/step - loss: 0.6607 - acc: 0.8639 - val_loss: 0.9730 - val_acc: 0.7940</span><br><span class=\"line\">Epoch 6/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 188us/step - loss: 0.5260 - acc: 0.8928 - val_loss: 0.9196 - val_acc: 0.8100</span><br><span class=\"line\">Epoch 7/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 183us/step - loss: 0.4292 - acc: 0.9116 - val_loss: 0.9124 - val_acc: 0.8030</span><br><span class=\"line\">Epoch 8/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 201us/step - loss: 0.3498 - acc: 0.9270 - val_loss: 0.8942 - val_acc: 0.8170</span><br><span class=\"line\">Epoch 9/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 194us/step - loss: 0.2894 - acc: 0.9385 - val_loss: 0.9147 - val_acc: 0.8060</span><br><span class=\"line\">Epoch 10/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 181us/step - loss: 0.2451 - acc: 0.9453 - val_loss: 0.9124 - val_acc: 0.8130</span><br><span class=\"line\">Epoch 11/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 175us/step - loss: 0.2102 - acc: 0.9484 - val_loss: 0.9480 - val_acc: 0.8120</span><br><span class=\"line\">Epoch 12/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 173us/step - loss: 0.1881 - acc: 0.9523 - val_loss: 0.9600 - val_acc: 0.8050</span><br><span class=\"line\">Epoch 13/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 189us/step - loss: 0.1662 - acc: 0.9526 - val_loss: 0.9964 - val_acc: 0.7960</span><br><span class=\"line\">Epoch 14/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 229us/step - loss: 0.1530 - acc: 0.9550 - val_loss: 0.9766 - val_acc: 0.8050</span><br><span class=\"line\">Epoch 15/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 194us/step - loss: 0.1457 - acc: 0.9548 - val_loss: 1.0243 - val_acc: 0.7970</span><br><span class=\"line\">Epoch 16/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 176us/step - loss: 0.1332 - acc: 0.9553 - val_loss: 1.0392 - val_acc: 0.8020</span><br><span class=\"line\">Epoch 17/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 171us/step - loss: 0.1260 - acc: 0.9553 - val_loss: 1.0396 - val_acc: 0.7980</span><br><span class=\"line\">Epoch 18/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 183us/step - loss: 0.1169 - acc: 0.9560 - val_loss: 1.0390 - val_acc: 0.8150</span><br><span class=\"line\">Epoch 19/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 182us/step - loss: 0.1165 - acc: 0.9569 - val_loss: 1.0301 - val_acc: 0.8090</span><br><span class=\"line\">Epoch 20/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 177us/step - loss: 0.1140 - acc: 0.9580 - val_loss: 1.0484 - val_acc: 0.8030</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#绘制训练损失和验证损失</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">loss = history.history[<span class=\"string\">'loss'</span>]</span><br><span class=\"line\">val_loss = history.history[<span class=\"string\">'val_loss'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">epochs = range(<span class=\"number\">1</span>, len(loss) + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(epochs, loss, <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Training loss'</span>)</span><br><span class=\"line\">plt.plot(epochs, val_loss, <span class=\"string\">'b'</span>, label=<span class=\"string\">'Validation loss'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Training and validation loss'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Loss'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras3/output_12_0.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.clf()</span><br><span class=\"line\"></span><br><span class=\"line\">acc = history.history[<span class=\"string\">'acc'</span>]</span><br><span class=\"line\">val_acc = history.history[<span class=\"string\">'val_acc'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(epochs, acc, <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Training acc'</span>)</span><br><span class=\"line\">plt.plot(epochs, val_acc, <span class=\"string\">'b'</span>, label=<span class=\"string\">'Validation acc'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Training and validation accuracy'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Accuracy'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras3/output_13_0.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model = models.Sequential()</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>, input_shape=(<span class=\"number\">10000</span>,)))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">46</span>, activation=<span class=\"string\">'softmax'</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">model.compile(optimizer=<span class=\"string\">'rmsprop'</span>, loss=<span class=\"string\">'categorical_crossentropy'</span>, metrics=[<span class=\"string\">'accuracy'</span>])</span><br><span class=\"line\">history = model.fit(partial_x_train, partial_y_train, epochs=<span class=\"number\">9</span>, batch_size=<span class=\"number\">512</span>, validation_data=(x_val, y_val))</span><br><span class=\"line\">results = model.evaluate(x_test, one_hot_test_labels)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Train on 7982 samples, validate on 1000 samples</span><br><span class=\"line\">Epoch 1/9</span><br><span class=\"line\">7982/7982 [==============================] - 4s 494us/step - loss: 2.5416 - acc: 0.5223 - val_loss: 1.6816 - val_acc: 0.6490</span><br><span class=\"line\">Epoch 2/9</span><br><span class=\"line\">7982/7982 [==============================] - 2s 271us/step - loss: 1.3779 - acc: 0.7096 - val_loss: 1.2817 - val_acc: 0.7240</span><br><span class=\"line\">Epoch 3/9</span><br><span class=\"line\">7982/7982 [==============================] - 2s 225us/step - loss: 1.0201 - acc: 0.7783 - val_loss: 1.1325 - val_acc: 0.7500</span><br><span class=\"line\">Epoch 4/9</span><br><span class=\"line\">7982/7982 [==============================] - 1s 182us/step - loss: 0.8026 - acc: 0.8237 - val_loss: 1.0541 - val_acc: 0.7580</span><br><span class=\"line\">Epoch 5/9</span><br><span class=\"line\">7982/7982 [==============================] - 1s 180us/step - loss: 0.6429 - acc: 0.8617 - val_loss: 0.9743 - val_acc: 0.8000</span><br><span class=\"line\">Epoch 6/9</span><br><span class=\"line\">7982/7982 [==============================] - 2s 191us/step - loss: 0.5152 - acc: 0.8933 - val_loss: 0.9122 - val_acc: 0.8130</span><br><span class=\"line\">Epoch 7/9</span><br><span class=\"line\">7982/7982 [==============================] - 1s 174us/step - loss: 0.4152 - acc: 0.9138 - val_loss: 0.8975 - val_acc: 0.8240</span><br><span class=\"line\">Epoch 8/9</span><br><span class=\"line\">7982/7982 [==============================] - 1s 170us/step - loss: 0.3377 - acc: 0.9276 - val_loss: 0.8781 - val_acc: 0.8240</span><br><span class=\"line\">Epoch 9/9</span><br><span class=\"line\">7982/7982 [==============================] - 2s 193us/step - loss: 0.2803 - acc: 0.9369 - val_loss: 0.9426 - val_acc: 0.8020</span><br><span class=\"line\">2246/2246 [==============================] - 1s 354us/step</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">results</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[1.0234324284567964, 0.7782724844698171]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#在新数据上生成预测结果</span></span><br><span class=\"line\">predictions = model.predict(x_test)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">predictions[<span class=\"number\">0</span>].shape</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(46,)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">np.sum(predictions[<span class=\"number\">0</span>])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0.99999994</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">np.argmax(predictions[<span class=\"number\">0</span>])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">predictions[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array([9.00706073e-06, 1.12914335e-04, 3.39240214e-05, 9.69965935e-01,</span><br><span class=\"line\">       1.83314960e-02, 1.24670180e-07, 7.63048884e-05, 3.95889074e-05,</span><br><span class=\"line\">       3.83749488e-03, 2.36399887e-06, 3.72867580e-05, 9.80967656e-04,</span><br><span class=\"line\">       5.15155261e-05, 2.07923913e-05, 5.04263471e-06, 1.48046838e-05,</span><br><span class=\"line\">       1.14349602e-03, 1.92527470e-04, 3.11047770e-04, 1.02656987e-03,</span><br><span class=\"line\">       1.14359299e-03, 5.38451481e-04, 4.49636536e-06, 7.14166526e-05,</span><br><span class=\"line\">       9.90290209e-06, 2.55455700e-04, 2.65549829e-06, 2.30972691e-05,</span><br><span class=\"line\">       5.41368354e-06, 1.46480859e-04, 2.82360037e-04, 1.54729976e-04,</span><br><span class=\"line\">       1.18201979e-05, 5.56262385e-05, 4.05374340e-05, 1.80534789e-05,</span><br><span class=\"line\">       1.31222856e-04, 5.19382884e-05, 1.25783903e-04, 2.72022764e-04,</span><br><span class=\"line\">       3.01298915e-05, 3.90922709e-04, 1.79568303e-06, 2.20499132e-05,</span><br><span class=\"line\">       6.57706141e-06, 1.01889082e-05], dtype=float32)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">predictions[<span class=\"number\">0</span>][<span class=\"number\">3</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0.96996593</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#单标签 多分类</span></span><br><span class=\"line\"><span class=\"comment\">#加载路透社数据集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.datasets <span class=\"keyword\">import</span> reuters</span><br><span class=\"line\">(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=<span class=\"number\">10000</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Using TensorFlow backend.</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz</span><br><span class=\"line\">2113536/2110848 [==============================] - 7s 3us/step</span><br></pre></td></tr></table></figure>","more":"<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">len(train_data)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">8982</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">len(test_data)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2246</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_data[<span class=\"number\">10</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[1,</span><br><span class=\"line\"> 245,</span><br><span class=\"line\"> 273,</span><br><span class=\"line\"> 207,</span><br><span class=\"line\"> 156,</span><br><span class=\"line\"> 53,</span><br><span class=\"line\"> 74,</span><br><span class=\"line\"> 160,</span><br><span class=\"line\"> 26,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 46,</span><br><span class=\"line\"> 296,</span><br><span class=\"line\"> 26,</span><br><span class=\"line\"> 39,</span><br><span class=\"line\"> 74,</span><br><span class=\"line\"> 2979,</span><br><span class=\"line\"> 3554,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 46,</span><br><span class=\"line\"> 4689,</span><br><span class=\"line\"> 4329,</span><br><span class=\"line\"> 86,</span><br><span class=\"line\"> 61,</span><br><span class=\"line\"> 3499,</span><br><span class=\"line\"> 4795,</span><br><span class=\"line\"> 14,</span><br><span class=\"line\"> 61,</span><br><span class=\"line\"> 451,</span><br><span class=\"line\"> 4329,</span><br><span class=\"line\"> 17,</span><br><span class=\"line\"> 12]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#将索引解码为新闻文本</span></span><br><span class=\"line\">word_index = reuters.get_word_index()</span><br><span class=\"line\">reverse_word_index = dict([(value, key) <span class=\"keyword\">for</span> (key, value) <span class=\"keyword\">in</span> word_index.items()])</span><br><span class=\"line\">decoded_newswire = <span class=\"string\">' '</span>.join([reverse_word_index.get(i - <span class=\"number\">3</span>, <span class=\"string\">'?'</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> train_data[<span class=\"number\">0</span>]])</span><br><span class=\"line\"><span class=\"comment\">#第一个新闻</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json</span><br><span class=\"line\">557056/550378 [==============================] - 7s 13us/step</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_labels[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#数据向量化</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">vectorize_sequences</span><span class=\"params\">(sequences, dimension=<span class=\"number\">10000</span>)</span>:</span></span><br><span class=\"line\">    results = np.zeros((len(sequences), dimension))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, sequence <span class=\"keyword\">in</span> enumerate(sequences):</span><br><span class=\"line\">        results[i, sequence] = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> results</span><br><span class=\"line\">x_train = vectorize_sequences(train_data)</span><br><span class=\"line\">x_test = vectorize_sequences(test_data)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#标签向量化</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">to_one_hot</span><span class=\"params\">(labels, dimension=<span class=\"number\">46</span>)</span>:</span></span><br><span class=\"line\">    results = np.zeros((len(labels), dimension))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, label <span class=\"keyword\">in</span> enumerate(labels):</span><br><span class=\"line\">        results[i, label] = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> results</span><br><span class=\"line\"></span><br><span class=\"line\">one_hot_train_labels = to_one_hot(train_labels)</span><br><span class=\"line\">one_hot_test_labels = to_one_hot(test_labels)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#构建网络 模型定义</span></span><br><span class=\"line\"><span class=\"comment\">#激活函数 输出在46个不同输出类别上的概率分布</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> models</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> layers</span><br><span class=\"line\"></span><br><span class=\"line\">model = models.Sequential()</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>, input_shape=(<span class=\"number\">10000</span>,)))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">46</span>, activation=<span class=\"string\">'softmax'</span>))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#编译模型</span></span><br><span class=\"line\"><span class=\"comment\">#分类交叉熵 衡量两个概率分布之间的距离</span></span><br><span class=\"line\">model.compile(optimizer=<span class=\"string\">'rmsprop'</span>, loss=<span class=\"string\">'categorical_crossentropy'</span>, metrics=[<span class=\"string\">'accuracy'</span>])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#留出验证集</span></span><br><span class=\"line\">x_val = x_train[:<span class=\"number\">1000</span>]</span><br><span class=\"line\">partial_x_train = x_train[<span class=\"number\">1000</span>:]</span><br><span class=\"line\"></span><br><span class=\"line\">y_val = one_hot_train_labels[:<span class=\"number\">1000</span>]</span><br><span class=\"line\">partial_y_train = one_hot_train_labels[<span class=\"number\">1000</span>:]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#训练模型</span></span><br><span class=\"line\">history = model.fit(partial_x_train, partial_y_train, epochs=<span class=\"number\">20</span>, batch_size=<span class=\"number\">512</span>, validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Train on 7982 samples, validate on 1000 samples</span><br><span class=\"line\">Epoch 1/20</span><br><span class=\"line\">7982/7982 [==============================] - 4s 452us/step - loss: 2.4979 - acc: 0.4915 - val_loss: 1.6824 - val_acc: 0.6470</span><br><span class=\"line\">Epoch 2/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 264us/step - loss: 1.3942 - acc: 0.7045 - val_loss: 1.2821 - val_acc: 0.7160</span><br><span class=\"line\">Epoch 3/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 212us/step - loss: 1.0509 - acc: 0.7686 - val_loss: 1.1187 - val_acc: 0.7640</span><br><span class=\"line\">Epoch 4/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 175us/step - loss: 0.8256 - acc: 0.8281 - val_loss: 1.0233 - val_acc: 0.7740</span><br><span class=\"line\">Epoch 5/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 175us/step - loss: 0.6607 - acc: 0.8639 - val_loss: 0.9730 - val_acc: 0.7940</span><br><span class=\"line\">Epoch 6/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 188us/step - loss: 0.5260 - acc: 0.8928 - val_loss: 0.9196 - val_acc: 0.8100</span><br><span class=\"line\">Epoch 7/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 183us/step - loss: 0.4292 - acc: 0.9116 - val_loss: 0.9124 - val_acc: 0.8030</span><br><span class=\"line\">Epoch 8/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 201us/step - loss: 0.3498 - acc: 0.9270 - val_loss: 0.8942 - val_acc: 0.8170</span><br><span class=\"line\">Epoch 9/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 194us/step - loss: 0.2894 - acc: 0.9385 - val_loss: 0.9147 - val_acc: 0.8060</span><br><span class=\"line\">Epoch 10/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 181us/step - loss: 0.2451 - acc: 0.9453 - val_loss: 0.9124 - val_acc: 0.8130</span><br><span class=\"line\">Epoch 11/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 175us/step - loss: 0.2102 - acc: 0.9484 - val_loss: 0.9480 - val_acc: 0.8120</span><br><span class=\"line\">Epoch 12/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 173us/step - loss: 0.1881 - acc: 0.9523 - val_loss: 0.9600 - val_acc: 0.8050</span><br><span class=\"line\">Epoch 13/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 189us/step - loss: 0.1662 - acc: 0.9526 - val_loss: 0.9964 - val_acc: 0.7960</span><br><span class=\"line\">Epoch 14/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 229us/step - loss: 0.1530 - acc: 0.9550 - val_loss: 0.9766 - val_acc: 0.8050</span><br><span class=\"line\">Epoch 15/20</span><br><span class=\"line\">7982/7982 [==============================] - 2s 194us/step - loss: 0.1457 - acc: 0.9548 - val_loss: 1.0243 - val_acc: 0.7970</span><br><span class=\"line\">Epoch 16/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 176us/step - loss: 0.1332 - acc: 0.9553 - val_loss: 1.0392 - val_acc: 0.8020</span><br><span class=\"line\">Epoch 17/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 171us/step - loss: 0.1260 - acc: 0.9553 - val_loss: 1.0396 - val_acc: 0.7980</span><br><span class=\"line\">Epoch 18/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 183us/step - loss: 0.1169 - acc: 0.9560 - val_loss: 1.0390 - val_acc: 0.8150</span><br><span class=\"line\">Epoch 19/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 182us/step - loss: 0.1165 - acc: 0.9569 - val_loss: 1.0301 - val_acc: 0.8090</span><br><span class=\"line\">Epoch 20/20</span><br><span class=\"line\">7982/7982 [==============================] - 1s 177us/step - loss: 0.1140 - acc: 0.9580 - val_loss: 1.0484 - val_acc: 0.8030</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#绘制训练损失和验证损失</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">loss = history.history[<span class=\"string\">'loss'</span>]</span><br><span class=\"line\">val_loss = history.history[<span class=\"string\">'val_loss'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">epochs = range(<span class=\"number\">1</span>, len(loss) + <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(epochs, loss, <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Training loss'</span>)</span><br><span class=\"line\">plt.plot(epochs, val_loss, <span class=\"string\">'b'</span>, label=<span class=\"string\">'Validation loss'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Training and validation loss'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Loss'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras3/output_12_0.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.clf()</span><br><span class=\"line\"></span><br><span class=\"line\">acc = history.history[<span class=\"string\">'acc'</span>]</span><br><span class=\"line\">val_acc = history.history[<span class=\"string\">'val_acc'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(epochs, acc, <span class=\"string\">'bo'</span>, label=<span class=\"string\">'Training acc'</span>)</span><br><span class=\"line\">plt.plot(epochs, val_acc, <span class=\"string\">'b'</span>, label=<span class=\"string\">'Validation acc'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'Training and validation accuracy'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Epochs'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'Accuracy'</span>)</span><br><span class=\"line\">plt.legend()</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/01/28/Keras3/output_13_0.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model = models.Sequential()</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>, input_shape=(<span class=\"number\">10000</span>,)))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">64</span>, activation=<span class=\"string\">'relu'</span>))</span><br><span class=\"line\">model.add(layers.Dense(<span class=\"number\">46</span>, activation=<span class=\"string\">'softmax'</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">model.compile(optimizer=<span class=\"string\">'rmsprop'</span>, loss=<span class=\"string\">'categorical_crossentropy'</span>, metrics=[<span class=\"string\">'accuracy'</span>])</span><br><span class=\"line\">history = model.fit(partial_x_train, partial_y_train, epochs=<span class=\"number\">9</span>, batch_size=<span class=\"number\">512</span>, validation_data=(x_val, y_val))</span><br><span class=\"line\">results = model.evaluate(x_test, one_hot_test_labels)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Train on 7982 samples, validate on 1000 samples</span><br><span class=\"line\">Epoch 1/9</span><br><span class=\"line\">7982/7982 [==============================] - 4s 494us/step - loss: 2.5416 - acc: 0.5223 - val_loss: 1.6816 - val_acc: 0.6490</span><br><span class=\"line\">Epoch 2/9</span><br><span class=\"line\">7982/7982 [==============================] - 2s 271us/step - loss: 1.3779 - acc: 0.7096 - val_loss: 1.2817 - val_acc: 0.7240</span><br><span class=\"line\">Epoch 3/9</span><br><span class=\"line\">7982/7982 [==============================] - 2s 225us/step - loss: 1.0201 - acc: 0.7783 - val_loss: 1.1325 - val_acc: 0.7500</span><br><span class=\"line\">Epoch 4/9</span><br><span class=\"line\">7982/7982 [==============================] - 1s 182us/step - loss: 0.8026 - acc: 0.8237 - val_loss: 1.0541 - val_acc: 0.7580</span><br><span class=\"line\">Epoch 5/9</span><br><span class=\"line\">7982/7982 [==============================] - 1s 180us/step - loss: 0.6429 - acc: 0.8617 - val_loss: 0.9743 - val_acc: 0.8000</span><br><span class=\"line\">Epoch 6/9</span><br><span class=\"line\">7982/7982 [==============================] - 2s 191us/step - loss: 0.5152 - acc: 0.8933 - val_loss: 0.9122 - val_acc: 0.8130</span><br><span class=\"line\">Epoch 7/9</span><br><span class=\"line\">7982/7982 [==============================] - 1s 174us/step - loss: 0.4152 - acc: 0.9138 - val_loss: 0.8975 - val_acc: 0.8240</span><br><span class=\"line\">Epoch 8/9</span><br><span class=\"line\">7982/7982 [==============================] - 1s 170us/step - loss: 0.3377 - acc: 0.9276 - val_loss: 0.8781 - val_acc: 0.8240</span><br><span class=\"line\">Epoch 9/9</span><br><span class=\"line\">7982/7982 [==============================] - 2s 193us/step - loss: 0.2803 - acc: 0.9369 - val_loss: 0.9426 - val_acc: 0.8020</span><br><span class=\"line\">2246/2246 [==============================] - 1s 354us/step</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">results</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[1.0234324284567964, 0.7782724844698171]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#在新数据上生成预测结果</span></span><br><span class=\"line\">predictions = model.predict(x_test)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">predictions[<span class=\"number\">0</span>].shape</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(46,)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">np.sum(predictions[<span class=\"number\">0</span>])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0.99999994</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">np.argmax(predictions[<span class=\"number\">0</span>])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">predictions[<span class=\"number\">0</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array([9.00706073e-06, 1.12914335e-04, 3.39240214e-05, 9.69965935e-01,</span><br><span class=\"line\">       1.83314960e-02, 1.24670180e-07, 7.63048884e-05, 3.95889074e-05,</span><br><span class=\"line\">       3.83749488e-03, 2.36399887e-06, 3.72867580e-05, 9.80967656e-04,</span><br><span class=\"line\">       5.15155261e-05, 2.07923913e-05, 5.04263471e-06, 1.48046838e-05,</span><br><span class=\"line\">       1.14349602e-03, 1.92527470e-04, 3.11047770e-04, 1.02656987e-03,</span><br><span class=\"line\">       1.14359299e-03, 5.38451481e-04, 4.49636536e-06, 7.14166526e-05,</span><br><span class=\"line\">       9.90290209e-06, 2.55455700e-04, 2.65549829e-06, 2.30972691e-05,</span><br><span class=\"line\">       5.41368354e-06, 1.46480859e-04, 2.82360037e-04, 1.54729976e-04,</span><br><span class=\"line\">       1.18201979e-05, 5.56262385e-05, 4.05374340e-05, 1.80534789e-05,</span><br><span class=\"line\">       1.31222856e-04, 5.19382884e-05, 1.25783903e-04, 2.72022764e-04,</span><br><span class=\"line\">       3.01298915e-05, 3.90922709e-04, 1.79568303e-06, 2.20499132e-05,</span><br><span class=\"line\">       6.57706141e-06, 1.01889082e-05], dtype=float32)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">predictions[<span class=\"number\">0</span>][<span class=\"number\">3</span>]</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">0.96996593</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>"},{"title":"Intellij IDEA插件开发入门（一）","date":"2019-01-27T13:13:10.000Z","photos":["0.png"],"_content":"\nIntellij IDEA插件开发有两种方式：\n\n* Gradle\n* Plugin Devkit\n\n本文根据官方推荐使用Gradle。\n\n## 1. 插件开发环境\n\n* IDEA: 社区版本\n* Project JDK: 1.8\n* Gradle: 4.10\n\n<!-- more -->\n\n## 2. 确认Gradle可用\n\n菜单Preferences -> Plugins\n\n![1](Plugin1/1.png)\n\n## 3. 创建Plugin项目\n\n![2](Plugin1/2.png)\n\n![3](Plugin1/3.png)\n\n![4](Plugin1/4.png)\n\n（官方推荐勾选“Use default cradle wrapper”，以便IDEA自动安装Gradle需要的包）\n\n![5](Plugin1/5.png)\n\n项目创建完成。\n\n**工程结构：**\n\n![](Plugin1/16.png)\n\n![6](Plugin1/17.png)\n\n**plugin.xml文件内容：**\n\n* id：当前插件的唯一id号。\n* name：插件的名称。\n* version：插件的版本号。\n* vendor：开发人的邮箱、公司名称。\n* description：插件的描述，如果将插件上传到IDEA的仓库，在进行下载时会显示该描述。\n* idea-version：表示当前插件所支持的所有IDEA版本。\n* extensions：一般放一些我们自己扩展的东西，比如新增高亮显示、新增语言支持。\n* actions：新增的类在这里注册，用于菜单栏扩展。\n\n## 4. 配置Gradle插件\n\n在build.gradle文件中，设置运行插件的沙箱地址。\n\n![7](Plugin1/7.png)\n\n## 5. 创建一个action\n\n![8](Plugin1/8.png)\n\n![9](Plugin1/9.png)\n\n自定义功能加在Window菜单栏下。\n\n![10](Plugin1/10.png)\n\n![11](Plugin1/11.png)\n\n在plugin.xml文件中，项目自动生成action配置：\n\n![12](Plugin1/12.png)\n\n## 6. Gradle运行配置\n\n菜单Edit Configurations -> Run/Debug Configurations\n\n点击'+'号，新建Gradle Run Configuration。\n\n![13](Plugin1/18.png)\n\n\n\n![14](Plugin1/19.png)\n\n![15](Plugin1/13.png)\n\n## 7. 运行项目\n\n![16](Plugin1/20.png)\n\n在Window菜单栏加入我们自定义的'Greeting'选项，点击弹出'Hello World!'。\n\n![17](Plugin1/14.png)\n\n![18](Plugin1/15.png)\n\n## 8. 打包插件\n\n参考文献：\n\nIDEA官方插件开发手册http://www.jetbrains.org/intellij/sdk/docs/basics.html\n\n","source":"_posts/Plugin1.md","raw":"---\ntitle: Intellij IDEA插件开发入门（一）\ndate: 2019-01-27 21:13:10\ntags:\n    - Intellij Plugin\ncategories:\n    - Notes\nphotos:\n    - 0.png\n---\n\nIntellij IDEA插件开发有两种方式：\n\n* Gradle\n* Plugin Devkit\n\n本文根据官方推荐使用Gradle。\n\n## 1. 插件开发环境\n\n* IDEA: 社区版本\n* Project JDK: 1.8\n* Gradle: 4.10\n\n<!-- more -->\n\n## 2. 确认Gradle可用\n\n菜单Preferences -> Plugins\n\n![1](Plugin1/1.png)\n\n## 3. 创建Plugin项目\n\n![2](Plugin1/2.png)\n\n![3](Plugin1/3.png)\n\n![4](Plugin1/4.png)\n\n（官方推荐勾选“Use default cradle wrapper”，以便IDEA自动安装Gradle需要的包）\n\n![5](Plugin1/5.png)\n\n项目创建完成。\n\n**工程结构：**\n\n![](Plugin1/16.png)\n\n![6](Plugin1/17.png)\n\n**plugin.xml文件内容：**\n\n* id：当前插件的唯一id号。\n* name：插件的名称。\n* version：插件的版本号。\n* vendor：开发人的邮箱、公司名称。\n* description：插件的描述，如果将插件上传到IDEA的仓库，在进行下载时会显示该描述。\n* idea-version：表示当前插件所支持的所有IDEA版本。\n* extensions：一般放一些我们自己扩展的东西，比如新增高亮显示、新增语言支持。\n* actions：新增的类在这里注册，用于菜单栏扩展。\n\n## 4. 配置Gradle插件\n\n在build.gradle文件中，设置运行插件的沙箱地址。\n\n![7](Plugin1/7.png)\n\n## 5. 创建一个action\n\n![8](Plugin1/8.png)\n\n![9](Plugin1/9.png)\n\n自定义功能加在Window菜单栏下。\n\n![10](Plugin1/10.png)\n\n![11](Plugin1/11.png)\n\n在plugin.xml文件中，项目自动生成action配置：\n\n![12](Plugin1/12.png)\n\n## 6. Gradle运行配置\n\n菜单Edit Configurations -> Run/Debug Configurations\n\n点击'+'号，新建Gradle Run Configuration。\n\n![13](Plugin1/18.png)\n\n\n\n![14](Plugin1/19.png)\n\n![15](Plugin1/13.png)\n\n## 7. 运行项目\n\n![16](Plugin1/20.png)\n\n在Window菜单栏加入我们自定义的'Greeting'选项，点击弹出'Hello World!'。\n\n![17](Plugin1/14.png)\n\n![18](Plugin1/15.png)\n\n## 8. 打包插件\n\n参考文献：\n\nIDEA官方插件开发手册http://www.jetbrains.org/intellij/sdk/docs/basics.html\n\n","slug":"Plugin1","published":1,"updated":"2019-01-28T09:28:47.278Z","comments":1,"layout":"post","link":"","_id":"cju3r7xhp000dapndfk6zvab7","content":"<p>Intellij IDEA插件开发有两种方式：</p>\n<ul>\n<li>Gradle</li>\n<li>Plugin Devkit</li>\n</ul>\n<p>本文根据官方推荐使用Gradle。</p>\n<h2 id=\"1-插件开发环境\"><a href=\"#1-插件开发环境\" class=\"headerlink\" title=\"1. 插件开发环境\"></a>1. 插件开发环境</h2><ul>\n<li>IDEA: 社区版本</li>\n<li>Project JDK: 1.8</li>\n<li>Gradle: 4.10</li>\n</ul>\n<a id=\"more\"></a>\n<h2 id=\"2-确认Gradle可用\"><a href=\"#2-确认Gradle可用\" class=\"headerlink\" title=\"2. 确认Gradle可用\"></a>2. 确认Gradle可用</h2><p>菜单Preferences -&gt; Plugins</p>\n<p><img src=\"/2019/01/27/Plugin1/1.png\" alt=\"1\"></p>\n<h2 id=\"3-创建Plugin项目\"><a href=\"#3-创建Plugin项目\" class=\"headerlink\" title=\"3. 创建Plugin项目\"></a>3. 创建Plugin项目</h2><p><img src=\"/2019/01/27/Plugin1/2.png\" alt=\"2\"></p>\n<p><img src=\"/2019/01/27/Plugin1/3.png\" alt=\"3\"></p>\n<p><img src=\"/2019/01/27/Plugin1/4.png\" alt=\"4\"></p>\n<p>（官方推荐勾选“Use default cradle wrapper”，以便IDEA自动安装Gradle需要的包）</p>\n<p><img src=\"/2019/01/27/Plugin1/5.png\" alt=\"5\"></p>\n<p>项目创建完成。</p>\n<p><strong>工程结构：</strong></p>\n<p><img src=\"/2019/01/27/Plugin1/16.png\" alt=\"\"></p>\n<p><img src=\"/2019/01/27/Plugin1/17.png\" alt=\"6\"></p>\n<p><strong>plugin.xml文件内容：</strong></p>\n<ul>\n<li>id：当前插件的唯一id号。</li>\n<li>name：插件的名称。</li>\n<li>version：插件的版本号。</li>\n<li>vendor：开发人的邮箱、公司名称。</li>\n<li>description：插件的描述，如果将插件上传到IDEA的仓库，在进行下载时会显示该描述。</li>\n<li>idea-version：表示当前插件所支持的所有IDEA版本。</li>\n<li>extensions：一般放一些我们自己扩展的东西，比如新增高亮显示、新增语言支持。</li>\n<li>actions：新增的类在这里注册，用于菜单栏扩展。</li>\n</ul>\n<h2 id=\"4-配置Gradle插件\"><a href=\"#4-配置Gradle插件\" class=\"headerlink\" title=\"4. 配置Gradle插件\"></a>4. 配置Gradle插件</h2><p>在build.gradle文件中，设置运行插件的沙箱地址。</p>\n<p><img src=\"/2019/01/27/Plugin1/7.png\" alt=\"7\"></p>\n<h2 id=\"5-创建一个action\"><a href=\"#5-创建一个action\" class=\"headerlink\" title=\"5. 创建一个action\"></a>5. 创建一个action</h2><p><img src=\"/2019/01/27/Plugin1/8.png\" alt=\"8\"></p>\n<p><img src=\"/2019/01/27/Plugin1/9.png\" alt=\"9\"></p>\n<p>自定义功能加在Window菜单栏下。</p>\n<p><img src=\"/2019/01/27/Plugin1/10.png\" alt=\"10\"></p>\n<p><img src=\"/2019/01/27/Plugin1/11.png\" alt=\"11\"></p>\n<p>在plugin.xml文件中，项目自动生成action配置：</p>\n<p><img src=\"/2019/01/27/Plugin1/12.png\" alt=\"12\"></p>\n<h2 id=\"6-Gradle运行配置\"><a href=\"#6-Gradle运行配置\" class=\"headerlink\" title=\"6. Gradle运行配置\"></a>6. Gradle运行配置</h2><p>菜单Edit Configurations -&gt; Run/Debug Configurations</p>\n<p>点击’+’号，新建Gradle Run Configuration。</p>\n<p><img src=\"/2019/01/27/Plugin1/18.png\" alt=\"13\"></p>\n<p><img src=\"/2019/01/27/Plugin1/19.png\" alt=\"14\"></p>\n<p><img src=\"/2019/01/27/Plugin1/13.png\" alt=\"15\"></p>\n<h2 id=\"7-运行项目\"><a href=\"#7-运行项目\" class=\"headerlink\" title=\"7. 运行项目\"></a>7. 运行项目</h2><p><img src=\"/2019/01/27/Plugin1/20.png\" alt=\"16\"></p>\n<p>在Window菜单栏加入我们自定义的’Greeting’选项，点击弹出’Hello World!’。</p>\n<p><img src=\"/2019/01/27/Plugin1/14.png\" alt=\"17\"></p>\n<p><img src=\"/2019/01/27/Plugin1/15.png\" alt=\"18\"></p>\n<h2 id=\"8-打包插件\"><a href=\"#8-打包插件\" class=\"headerlink\" title=\"8. 打包插件\"></a>8. 打包插件</h2><p>参考文献：</p>\n<p>IDEA官方插件开发手册<a href=\"http://www.jetbrains.org/intellij/sdk/docs/basics.html\" target=\"_blank\" rel=\"noopener\">http://www.jetbrains.org/intellij/sdk/docs/basics.html</a></p>\n","site":{"data":{}},"excerpt":"<p>Intellij IDEA插件开发有两种方式：</p>\n<ul>\n<li>Gradle</li>\n<li>Plugin Devkit</li>\n</ul>\n<p>本文根据官方推荐使用Gradle。</p>\n<h2 id=\"1-插件开发环境\"><a href=\"#1-插件开发环境\" class=\"headerlink\" title=\"1. 插件开发环境\"></a>1. 插件开发环境</h2><ul>\n<li>IDEA: 社区版本</li>\n<li>Project JDK: 1.8</li>\n<li>Gradle: 4.10</li>\n</ul>","more":"<h2 id=\"2-确认Gradle可用\"><a href=\"#2-确认Gradle可用\" class=\"headerlink\" title=\"2. 确认Gradle可用\"></a>2. 确认Gradle可用</h2><p>菜单Preferences -&gt; Plugins</p>\n<p><img src=\"/2019/01/27/Plugin1/1.png\" alt=\"1\"></p>\n<h2 id=\"3-创建Plugin项目\"><a href=\"#3-创建Plugin项目\" class=\"headerlink\" title=\"3. 创建Plugin项目\"></a>3. 创建Plugin项目</h2><p><img src=\"/2019/01/27/Plugin1/2.png\" alt=\"2\"></p>\n<p><img src=\"/2019/01/27/Plugin1/3.png\" alt=\"3\"></p>\n<p><img src=\"/2019/01/27/Plugin1/4.png\" alt=\"4\"></p>\n<p>（官方推荐勾选“Use default cradle wrapper”，以便IDEA自动安装Gradle需要的包）</p>\n<p><img src=\"/2019/01/27/Plugin1/5.png\" alt=\"5\"></p>\n<p>项目创建完成。</p>\n<p><strong>工程结构：</strong></p>\n<p><img src=\"/2019/01/27/Plugin1/16.png\" alt=\"\"></p>\n<p><img src=\"/2019/01/27/Plugin1/17.png\" alt=\"6\"></p>\n<p><strong>plugin.xml文件内容：</strong></p>\n<ul>\n<li>id：当前插件的唯一id号。</li>\n<li>name：插件的名称。</li>\n<li>version：插件的版本号。</li>\n<li>vendor：开发人的邮箱、公司名称。</li>\n<li>description：插件的描述，如果将插件上传到IDEA的仓库，在进行下载时会显示该描述。</li>\n<li>idea-version：表示当前插件所支持的所有IDEA版本。</li>\n<li>extensions：一般放一些我们自己扩展的东西，比如新增高亮显示、新增语言支持。</li>\n<li>actions：新增的类在这里注册，用于菜单栏扩展。</li>\n</ul>\n<h2 id=\"4-配置Gradle插件\"><a href=\"#4-配置Gradle插件\" class=\"headerlink\" title=\"4. 配置Gradle插件\"></a>4. 配置Gradle插件</h2><p>在build.gradle文件中，设置运行插件的沙箱地址。</p>\n<p><img src=\"/2019/01/27/Plugin1/7.png\" alt=\"7\"></p>\n<h2 id=\"5-创建一个action\"><a href=\"#5-创建一个action\" class=\"headerlink\" title=\"5. 创建一个action\"></a>5. 创建一个action</h2><p><img src=\"/2019/01/27/Plugin1/8.png\" alt=\"8\"></p>\n<p><img src=\"/2019/01/27/Plugin1/9.png\" alt=\"9\"></p>\n<p>自定义功能加在Window菜单栏下。</p>\n<p><img src=\"/2019/01/27/Plugin1/10.png\" alt=\"10\"></p>\n<p><img src=\"/2019/01/27/Plugin1/11.png\" alt=\"11\"></p>\n<p>在plugin.xml文件中，项目自动生成action配置：</p>\n<p><img src=\"/2019/01/27/Plugin1/12.png\" alt=\"12\"></p>\n<h2 id=\"6-Gradle运行配置\"><a href=\"#6-Gradle运行配置\" class=\"headerlink\" title=\"6. Gradle运行配置\"></a>6. Gradle运行配置</h2><p>菜单Edit Configurations -&gt; Run/Debug Configurations</p>\n<p>点击’+’号，新建Gradle Run Configuration。</p>\n<p><img src=\"/2019/01/27/Plugin1/18.png\" alt=\"13\"></p>\n<p><img src=\"/2019/01/27/Plugin1/19.png\" alt=\"14\"></p>\n<p><img src=\"/2019/01/27/Plugin1/13.png\" alt=\"15\"></p>\n<h2 id=\"7-运行项目\"><a href=\"#7-运行项目\" class=\"headerlink\" title=\"7. 运行项目\"></a>7. 运行项目</h2><p><img src=\"/2019/01/27/Plugin1/20.png\" alt=\"16\"></p>\n<p>在Window菜单栏加入我们自定义的’Greeting’选项，点击弹出’Hello World!’。</p>\n<p><img src=\"/2019/01/27/Plugin1/14.png\" alt=\"17\"></p>\n<p><img src=\"/2019/01/27/Plugin1/15.png\" alt=\"18\"></p>\n<h2 id=\"8-打包插件\"><a href=\"#8-打包插件\" class=\"headerlink\" title=\"8. 打包插件\"></a>8. 打包插件</h2><p>参考文献：</p>\n<p>IDEA官方插件开发手册<a href=\"http://www.jetbrains.org/intellij/sdk/docs/basics.html\" target=\"_blank\" rel=\"noopener\">http://www.jetbrains.org/intellij/sdk/docs/basics.html</a></p>"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n<!-- less -->\n\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n<!-- less -->\n\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"date":"2019-01-18T11:46:20.519Z","updated":"2019-01-24T11:03:39.496Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju3r7xhs000fapndkyuagt8z","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>","site":{"data":{}},"excerpt":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>"}],"PostAsset":[{"_id":"source/_posts/Keras4/output_11_0.png","slug":"output_11_0.png","post":"cju3r7xhg0006apnddn1kso7m","modified":0,"renderable":0},{"_id":"source/_posts/Keras4/output_12_0.png","slug":"output_12_0.png","post":"cju3r7xhg0006apnddn1kso7m","modified":0,"renderable":0},{"_id":"source/_posts/Keras3/output_12_0.png","slug":"output_12_0.png","post":"cju3r7xhl0009apndx9qo4zs1","modified":0,"renderable":0},{"_id":"source/_posts/Keras3/output_13_0.png","slug":"output_13_0.png","post":"cju3r7xhl0009apndx9qo4zs1","modified":0,"renderable":0},{"_id":"source/_posts/Keras2/0.png","slug":"0.png","post":"cju3r7xh40000apndr9bepu33","modified":0,"renderable":0},{"_id":"source/_posts/Keras2/output_15_0.png","slug":"output_15_0.png","post":"cju3r7xh40000apndr9bepu33","modified":0,"renderable":0},{"_id":"source/_posts/Keras2/电影评级分类：二分类问题.pdf","slug":"电影评级分类：二分类问题.pdf","post":"cju3r7xh40000apndr9bepu33","modified":0,"renderable":0},{"_id":"source/_posts/Keras1/1.png","slug":"1.png","post":"cju3r7xha0002apndr8450cdt","modified":0,"renderable":0},{"_id":"source/_posts/Keras1/install-keras.png","slug":"install-keras.png","post":"cju3r7xha0002apndr8450cdt","modified":0,"renderable":0},{"_id":"source/_posts/Keras1/install-python-3-6-2.png","slug":"install-python-3-6-2.png","post":"cju3r7xha0002apndr8450cdt","modified":0,"renderable":0},{"_id":"source/_posts/Keras1/install-python-3-6.jpg","slug":"install-python-3-6.jpg","post":"cju3r7xha0002apndr8450cdt","modified":0,"renderable":0},{"_id":"source/_posts/Keras1/keras-test.png","slug":"keras-test.png","post":"cju3r7xha0002apndr8450cdt","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/0.png","slug":"0.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/1.png","slug":"1.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/10.png","slug":"10.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/11.png","slug":"11.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/12.png","slug":"12.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/13.png","slug":"13.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/14.png","slug":"14.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/15.png","slug":"15.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/16.png","slug":"16.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/17.png","slug":"17.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/18.png","slug":"18.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/19.png","slug":"19.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/2.png","slug":"2.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/20.png","slug":"20.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/3.png","slug":"3.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/4.png","slug":"4.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/5.png","slug":"5.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/6.png","slug":"6.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/7.png","slug":"7.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/8.png","slug":"8.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0},{"_id":"source/_posts/Plugin1/9.png","slug":"9.png","post":"cju3r7xhp000dapndfk6zvab7","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cju3r7xh40000apndr9bepu33","category_id":"cju3r7xhe0004apndyt4xlfos","_id":"cju3r7xhu000hapndyqa7do5d"},{"post_id":"cju3r7xhl0009apndx9qo4zs1","category_id":"cju3r7xhe0004apndyt4xlfos","_id":"cju3r7xhx000kapndn2c512uu"},{"post_id":"cju3r7xhp000dapndfk6zvab7","category_id":"cju3r7xhe0004apndyt4xlfos","_id":"cju3r7xhy000lapnddvrmgq6d"},{"post_id":"cju3r7xha0002apndr8450cdt","category_id":"cju3r7xhe0004apndyt4xlfos","_id":"cju3r7xhz000oapndifm03l5b"},{"post_id":"cju3r7xhg0006apnddn1kso7m","category_id":"cju3r7xhe0004apndyt4xlfos","_id":"cju3r7xhz000papndyo8wbewi"}],"PostTag":[{"post_id":"cju3r7xh40000apndr9bepu33","tag_id":"cju3r7xhg0005apndw5m0x5ts","_id":"cju3r7xho000capndiy45rbvm"},{"post_id":"cju3r7xhl0009apndx9qo4zs1","tag_id":"cju3r7xhg0005apndw5m0x5ts","_id":"cju3r7xhs000eapndnaksilok"},{"post_id":"cju3r7xha0002apndr8450cdt","tag_id":"cju3r7xhg0005apndw5m0x5ts","_id":"cju3r7xhx000japnd5vmvvryy"},{"post_id":"cju3r7xhg0006apnddn1kso7m","tag_id":"cju3r7xhg0005apndw5m0x5ts","_id":"cju3r7xhz000napndyag05m3a"},{"post_id":"cju3r7xhp000dapndfk6zvab7","tag_id":"cju3r7xhy000mapndzkkzd4we","_id":"cju3r7xhz000qapnd4j8eevuz"}],"Tag":[{"name":"Keras","_id":"cju3r7xhg0005apndw5m0x5ts"},{"name":"Intellij Plugin","_id":"cju3r7xhy000mapndzkkzd4we"}]}}